{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "459ef6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from typing import List, Tuple\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "seed = 123456\n",
    "np.random.seed(seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215217a3",
   "metadata": {},
   "source": [
    "# –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –º–æ–¥–µ–ª–∏\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "731c677a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualHeadChessDataset(Dataset):\n",
    "    def __init__(self, csv_file: str):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "\n",
    "        self._validate_data()\n",
    "        self.piece_to_idx = {\n",
    "            \"P\": 0,\n",
    "            \"N\": 1,\n",
    "            \"B\": 2,\n",
    "            \"R\": 3,\n",
    "            \"Q\": 4,\n",
    "            \"K\": 5,\n",
    "            \"p\": 6,\n",
    "            \"n\": 7,\n",
    "            \"b\": 8,\n",
    "            \"r\": 9,\n",
    "            \"q\": 10,\n",
    "            \"k\": 11,\n",
    "        }\n",
    "\n",
    "    def _validate_data(self):\n",
    "        valid_indices = []\n",
    "        for idx, row in self.df.iterrows():\n",
    "            try:\n",
    "                board = chess.Board(row[\"fen\"])\n",
    "                move = chess.Move.from_uci(row[\"move\"])\n",
    "                if move in board.legal_moves:\n",
    "                    valid_indices.append(idx)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        self.df = self.df.loc[valid_indices].reset_index(drop=True)\n",
    "        print(f\"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.df)} –≤–∞–ª–∏–¥–Ω—ã—Ö –ø–æ–∑–∏—Ü–∏–π\")\n",
    "\n",
    "    def _board_to_tensor(self, fen: str) -> torch.Tensor:\n",
    "        board = chess.Board(fen)\n",
    "        tensor = torch.zeros(20, 8, 8, dtype=torch.float32)\n",
    "\n",
    "        # –§–∏–≥—É—Ä—ã (–ø–ª–æ—Å–∫–æ—Å—Ç–∏ 0-11)\n",
    "        for square in chess.SQUARES:\n",
    "            piece = board.piece_at(square)\n",
    "            if piece:\n",
    "                row, col = square // 8, square % 8\n",
    "                piece_idx = self.piece_to_idx[piece.symbol()]\n",
    "                tensor[piece_idx, row, col] = 1.0\n",
    "\n",
    "        # –ß–µ–π —Ö–æ–¥ (–ø–ª–æ—Å–∫–æ—Å—Ç—å 12)\n",
    "        tensor[12] = 1.0 if board.turn else 0.0\n",
    "\n",
    "        # –†–æ–∫–∏—Ä–æ–≤–∫–∏ (–ø–ª–æ—Å–∫–æ—Å—Ç–∏ 13-16)\n",
    "        castling_rights = [\n",
    "            board.has_kingside_castling_rights(chess.WHITE),\n",
    "            board.has_queenside_castling_rights(chess.WHITE),\n",
    "            board.has_kingside_castling_rights(chess.BLACK),\n",
    "            board.has_queenside_castling_rights(chess.BLACK),\n",
    "        ]\n",
    "        for i, has_right in enumerate(castling_rights):\n",
    "            if has_right:\n",
    "                tensor[13 + i] = 1.0\n",
    "\n",
    "        # –í–∑—è—Ç–∏–µ –Ω–∞ –ø—Ä–æ—Ö–æ–¥–µ (–ø–ª–æ—Å–∫–æ—Å—Ç—å 17)\n",
    "        if board.ep_square is not None:\n",
    "            row, col = board.ep_square // 8, board.ep_square % 8\n",
    "            tensor[17, row, col] = 1.0\n",
    "\n",
    "        # –°—á–µ—Ç—á–∏–∫ –ø–æ–ª—É—Ö–æ–¥–æ–≤ (–ø–ª–æ—Å–∫–æ—Å—Ç—å 18)\n",
    "        tensor[18] = board.halfmove_clock / 50.0\n",
    "\n",
    "        # –ù–æ–º–µ—Ä —Ö–æ–¥–∞ (–ø–ª–æ—Å–∫–æ—Å—Ç—å 19)\n",
    "        tensor[19] = board.fullmove_number / 500.0\n",
    "\n",
    "        return tensor\n",
    "\n",
    "    def _move_to_dual_labels(self, move_uci: str, fen: str) -> tuple:\n",
    "        board = chess.Board(fen)\n",
    "        move = chess.Move.from_uci(move_uci)\n",
    "\n",
    "        from_square = move.from_square\n",
    "\n",
    "        # –î–ª—è to_square —É—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–µ–≤—Ä–∞—â–µ–Ω–∏—è\n",
    "        # –î–ò–ê–ü–ê–ó–û–ù –î–û–õ–ñ–ï–ù –ë–´–¢–¨ 0-68 (69 –∫–ª–∞—Å—Å–æ–≤)\n",
    "        # print(move.promotion)\n",
    "        if move.promotion:\n",
    "            # –ö–æ–¥–∏—Ä—É–µ–º –ø—Ä–µ–≤—Ä–∞—â–µ–Ω–∏—è: 64-68\n",
    "            to_square = 64 + (move.promotion - 1)  # 64, 65, 66, 67, 68\n",
    "        else:\n",
    "            to_square = move.to_square  # 0-63\n",
    "\n",
    "        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ to_square –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ\n",
    "        if to_square >= 69:\n",
    "            raise ValueError(f\"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π to_square: {to_square} –¥–ª—è —Ö–æ–¥–∞ {move_uci}\")\n",
    "\n",
    "        return from_square, to_square\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        fen = row[\"fen\"]\n",
    "        move = row[\"move\"]\n",
    "\n",
    "        board_tensor = self._board_to_tensor(fen)\n",
    "        from_label, to_label = self._move_to_dual_labels(move, fen)\n",
    "\n",
    "        return board_tensor, from_label, to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d81e9b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessDataSplitter:\n",
    "    def __init__(\n",
    "        self,\n",
    "        csv_file,\n",
    "        train_ratio=0.7,\n",
    "        val_ratio=0.15,\n",
    "        test_ratio=0.15,\n",
    "        random_state=42,\n",
    "    ):\n",
    "        print(train_ratio, val_ratio, test_ratio)\n",
    "        assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6, (\n",
    "            \"–°—É–º–º–∞ –¥–æ–ª–µ–π –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Ä–∞–≤–Ω–∞ 1\"\n",
    "        )\n",
    "\n",
    "        self.csv_file = csv_file\n",
    "        self.train_ratio = train_ratio\n",
    "        self.val_ratio = val_ratio\n",
    "        self.test_ratio = test_ratio\n",
    "        self.random_state = random_state\n",
    "\n",
    "        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–æ–ª–Ω—ã–π dataset\n",
    "        self.full_dataset = DualHeadChessDataset(csv_file)\n",
    "\n",
    "    def split_data(self):\n",
    "        \"\"\"–†–∞–∑–±–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –Ω–∞ train/val/test\"\"\"\n",
    "        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã\n",
    "        n_total = len(self.full_dataset)\n",
    "        indices = list(range(n_total))\n",
    "\n",
    "        # –ü–µ—Ä–≤–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ: –æ—Ç–¥–µ–ª—è–µ–º test\n",
    "        train_val_idx, test_idx = train_test_split(\n",
    "            indices,\n",
    "            test_size=self.test_ratio,\n",
    "            random_state=self.random_state,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "        # –í—Ç–æ—Ä–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ: —Ä–∞–∑–¥–µ–ª—è–µ–º train –∏ val\n",
    "        train_idx, val_idx = train_test_split(\n",
    "            train_val_idx,\n",
    "            test_size=self.val_ratio / (self.train_ratio + self.val_ratio),\n",
    "            random_state=self.random_state,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "        # –°–æ–∑–¥–∞–µ–º Subset datasets\n",
    "        train_dataset = Subset(self.full_dataset, train_idx)\n",
    "        val_dataset = Subset(self.full_dataset, val_idx)\n",
    "        test_dataset = Subset(self.full_dataset, test_idx)\n",
    "\n",
    "        print(f\"–†–∞–∑–±–∏–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ:\")\n",
    "        print(\n",
    "            f\"Train: {len(train_dataset)} samples ({len(train_dataset) / n_total * 100:.1f}%)\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Val: {len(val_dataset)} samples ({len(val_dataset) / n_total * 100:.1f}%)\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Test: {len(test_dataset)} samples ({len(test_dataset) / n_total * 100:.1f}%)\"\n",
    "        )\n",
    "\n",
    "        return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d1ed00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(channels, channels, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(channels, channels, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(channels)\n",
    "        self.bn2 = nn.BatchNorm2d(channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x += residual\n",
    "        return F.relu(x)\n",
    "\n",
    "\n",
    "class ChessResNetWithAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initial convolution\n",
    "        self.conv_input = nn.Conv2d(20, 256, 3, padding=1)\n",
    "        self.bn_input = nn.BatchNorm2d(256)\n",
    "\n",
    "        # Residual blocks\n",
    "        self.res_blocks = nn.Sequential(*[ResidualBlock(256) for _ in range(5)])\n",
    "\n",
    "        # Attention mechanism\n",
    "        self.attention_conv = nn.Conv2d(256, 1, 1)\n",
    "\n",
    "        # Policy head\n",
    "        self.policy_conv = nn.Conv2d(256, 69, 1)  # 64 moves + 5 promotions\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Feature extraction\n",
    "        x = F.relu(self.bn_input(self.conv_input(x)))\n",
    "        x = self.res_blocks(x)\n",
    "\n",
    "        # Spatial attention\n",
    "        attention_weights = F.softmax(\n",
    "            self.attention_conv(x).view(x.size(0), -1), dim=1\n",
    "        ).view(x.size(0), 1, 8, 8)\n",
    "\n",
    "        # Apply attention\n",
    "        x_attended = x * attention_weights\n",
    "\n",
    "        # Policy head\n",
    "        policy = self.policy_conv(x_attended)\n",
    "        policy = policy.view(policy.size(0), 69, 64)  # [batch, move_types, squares]\n",
    "\n",
    "        return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9842fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessTrainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        test_loader,\n",
    "        device=\"cpu\",\n",
    "        lr=0.01,\n",
    "        weight_decay=0.1,\n",
    "    ):\n",
    "        self.model = model.to(device)\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.device = device\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "\n",
    "        # –§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å –¥–ª—è policy head\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä\n",
    "        self.optimizer = optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=self.lr,  # –£–º–µ–Ω—å—à–∏–ª learning rate –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏\n",
    "            weight_decay=self.weight_decay,\n",
    "        )\n",
    "\n",
    "        # –ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ learning rate\n",
    "        self.scheduler = optim.lr_scheduler.StepLR(\n",
    "            self.optimizer, step_size=5, gamma=3 * self.lr\n",
    "        )\n",
    "\n",
    "        # –ò—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è\n",
    "        self.history = {\n",
    "            \"train_loss\": [],\n",
    "            \"val_loss\": [],\n",
    "            \"train_accuracy\": [],\n",
    "            \"val_accuracy\": [],\n",
    "            \"learning_rate\": [],\n",
    "        }\n",
    "\n",
    "    def _policy_to_move_labels(self, policy_output, from_targets, to_targets):\n",
    "        \"\"\"\n",
    "        –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç policy output [batch, 69, 64] –≤ –º–µ—Ç–∫–∏ —Ö–æ–¥–æ–≤\n",
    "        –∏ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Å —Ü–µ–ª–µ–≤—ã–º–∏ –º–µ—Ç–∫–∞–º–∏\n",
    "        \"\"\"\n",
    "        batch_size = policy_output.size(0)\n",
    "\n",
    "        # –°–æ–∑–¥–∞–µ–º —Ü–µ–ª–µ–≤—ã–µ –º–µ—Ç–∫–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ [batch, 4672]\n",
    "        target_labels = []\n",
    "        for i in range(batch_size):\n",
    "            from_sq = from_targets[i].item()\n",
    "            to_sq = to_targets[i].item()\n",
    "\n",
    "            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Ö–æ–¥–∞\n",
    "            if to_sq >= 64:\n",
    "                # –•–æ–¥ —Å –ø—Ä–µ–≤—Ä–∞—â–µ–Ω–∏–µ–º\n",
    "                promotion_type = to_sq - 64  # 0-3\n",
    "                move_label = from_sq * 69 + (64 + promotion_type)\n",
    "            else:\n",
    "                # –û–±—ã—á–Ω—ã–π —Ö–æ–¥\n",
    "                move_label = from_sq * 69 + to_sq\n",
    "\n",
    "            target_labels.append(move_label)\n",
    "\n",
    "        return torch.tensor(target_labels, device=self.device)\n",
    "\n",
    "    def _decode_policy_prediction(self, policy_output):\n",
    "        \"\"\"\n",
    "        –î–µ–∫–æ–¥–∏—Ä—É–µ—Ç policy output –≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ from_square –∏ to_square\n",
    "        \"\"\"\n",
    "        batch_size = policy_output.size(0)\n",
    "\n",
    "        # Reshape to [batch, 4672]\n",
    "        policy_flat = policy_output.view(batch_size, -1)\n",
    "\n",
    "        # –ù–∞—Ö–æ–¥–∏–º –Ω–∞–∏–±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω—ã–π —Ö–æ–¥\n",
    "        move_preds = torch.argmax(policy_flat, dim=1)\n",
    "\n",
    "        from_preds = move_preds // 73\n",
    "        move_type = move_preds % 73\n",
    "\n",
    "        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º to_square –∏ promotion\n",
    "        to_preds = []\n",
    "        promo_preds = []\n",
    "        for move_type_val in move_type:\n",
    "            if move_type_val >= 64:\n",
    "                # –•–æ–¥ —Å –ø—Ä–µ–≤—Ä–∞—â–µ–Ω–∏–µ–º\n",
    "                to_preds.append(move_type_val - 64)  # to_square –¥–ª—è –ø—Ä–µ–≤—Ä–∞—â–µ–Ω–∏–π\n",
    "                promo_preds.append(move_type_val - 63)  # 1=queen, 2=rook, etc.\n",
    "            else:\n",
    "                # –û–±—ã—á–Ω—ã–π —Ö–æ–¥\n",
    "                to_preds.append(move_type_val)\n",
    "                promo_preds.append(0)\n",
    "\n",
    "        return (from_preds.cpu(), torch.tensor(to_preds), torch.tensor(promo_preds))\n",
    "\n",
    "    def train_epoch(self):\n",
    "        \"\"\"–û–¥–Ω–∞ —ç–ø–æ—Ö–∞ –æ–±—É—á–µ–Ω–∏—è\"\"\"\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        train_bar = tqdm(self.train_loader, desc=\"Training\")\n",
    "\n",
    "        for batch_idx, (boards, from_targets, to_targets) in enumerate(train_bar):\n",
    "            # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ device\n",
    "            boards = boards.to(self.device)\n",
    "            from_targets = from_targets.to(self.device)\n",
    "            to_targets = to_targets.to(self.device)\n",
    "\n",
    "            # –û–±–Ω—É–ª—è–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥\n",
    "            policy_output = self.model(boards)  # [batch, 69, 64]\n",
    "\n",
    "            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º policy output –≤ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è loss\n",
    "            policy_flat = policy_output.view(policy_output.size(0), -1)  # [batch, 4672]\n",
    "\n",
    "            # –°–æ–∑–¥–∞–µ–º —Ü–µ–ª–µ–≤—ã–µ –º–µ—Ç–∫–∏\n",
    "            target_labels = self._policy_to_move_labels(\n",
    "                policy_output, from_targets, to_targets\n",
    "            )\n",
    "\n",
    "            # –í—ã—á–∏—Å–ª—è–µ–º –ø–æ—Ç–µ—Ä–∏\n",
    "            loss = self.criterion(policy_flat, target_labels)\n",
    "\n",
    "            # –û–±—Ä–∞—Ç–Ω—ã–π –ø—Ä–æ—Ö–æ–¥\n",
    "            loss.backward()\n",
    "\n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "\n",
    "            # –®–∞–≥ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞\n",
    "            self.optimizer.step()\n",
    "\n",
    "            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n",
    "            total_loss += loss.item()\n",
    "            batch_size = boards.size(0)\n",
    "            total_samples += batch_size\n",
    "\n",
    "            # –¢–æ—á–Ω–æ—Å—Ç—å\n",
    "            preds = torch.argmax(policy_flat, dim=1)\n",
    "            correct = (preds == target_labels).sum().item()\n",
    "            total_correct += correct\n",
    "\n",
    "            # –û–±–Ω–æ–≤–ª—è–µ–º progress bar\n",
    "            train_bar.set_postfix(\n",
    "                {\n",
    "                    \"Loss\": f\"{loss.item():.4f}\",\n",
    "                    \"Accuracy\": f\"{correct / batch_size:.3f}\",\n",
    "                }\n",
    "            )\n",
    "\n",
    "        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –∑–∞ —ç–ø–æ—Ö—É\n",
    "        avg_loss = total_loss / len(self.train_loader)\n",
    "        accuracy = total_correct / total_samples\n",
    "\n",
    "        return avg_loss, accuracy\n",
    "\n",
    "    def validate(self):\n",
    "        \"\"\"–í–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–∏\"\"\"\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for boards, from_targets, to_targets in tqdm(\n",
    "                self.val_loader, desc=\"Validation\"\n",
    "            ):\n",
    "                boards = boards.to(self.device)\n",
    "                from_targets = from_targets.to(self.device)\n",
    "                to_targets = to_targets.to(self.device)\n",
    "\n",
    "                # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥\n",
    "                policy_output = self.model(boards)\n",
    "                policy_flat = policy_output.view(policy_output.size(0), -1)\n",
    "\n",
    "                # –¶–µ–ª–µ–≤—ã–µ –º–µ—Ç–∫–∏\n",
    "                target_labels = self._policy_to_move_labels(\n",
    "                    policy_output, from_targets, to_targets\n",
    "                )\n",
    "\n",
    "                # –ü–æ—Ç–µ—Ä–∏\n",
    "                loss = self.criterion(policy_flat, target_labels)\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                batch_size = boards.size(0)\n",
    "                total_samples += batch_size\n",
    "\n",
    "                # –¢–æ—á–Ω–æ—Å—Ç—å\n",
    "                preds = torch.argmax(policy_flat, dim=1)\n",
    "                correct = (preds == target_labels).sum().item()\n",
    "                total_correct += correct\n",
    "\n",
    "        avg_loss = total_loss / len(self.val_loader)\n",
    "        accuracy = total_correct / total_samples\n",
    "\n",
    "        return avg_loss, accuracy\n",
    "\n",
    "    def train(self, num_epochs=50, early_stopping_patience=10):\n",
    "        \"\"\"–ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è\"\"\"\n",
    "        best_val_loss = float(\"inf\")\n",
    "        patience_counter = 0\n",
    "\n",
    "        print(\"–ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è ResNet –º–æ–¥–µ–ª–∏...\")\n",
    "        print(f\"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device}\")\n",
    "        print(f\"–†–∞–∑–º–µ—Ä —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞: {len(self.train_loader.dataset)}\")\n",
    "        print(f\"–†–∞–∑–º–µ—Ä –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞: {len(self.val_loader.dataset)}\")\n",
    "        print(f\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤: 4672\")\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f\"\\n–≠–ø–æ—Ö–∞ {epoch + 1}/{num_epochs}\")\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "            # –û–±—É—á–µ–Ω–∏–µ\n",
    "            train_loss, train_acc = self.train_epoch()\n",
    "\n",
    "            # –í–∞–ª–∏–¥–∞—Ü–∏—è\n",
    "            val_loss, val_acc = self.validate()\n",
    "\n",
    "            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ learning rate\n",
    "            self.scheduler.step(val_loss)\n",
    "            current_lr = self.optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—é\n",
    "            self.history[\"train_loss\"].append(train_loss)\n",
    "            self.history[\"val_loss\"].append(val_loss)\n",
    "            self.history[\"train_accuracy\"].append(train_acc)\n",
    "            self.history[\"val_accuracy\"].append(val_acc)\n",
    "            self.history[\"learning_rate\"].append(current_lr)\n",
    "\n",
    "            # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "            print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "            print(f\"Train Accuracy: {train_acc:.4f} | Val Accuracy: {val_acc:.4f}\")\n",
    "            print(f\"Learning Rate: {current_lr:.6f}\")\n",
    "\n",
    "            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                patience_counter = 0\n",
    "                self.save_model(\"best_chess_resnet_model.pth\")\n",
    "                print(\"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –ª—É—á—à–∞—è –º–æ–¥–µ–ª—å!\")\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                print(\n",
    "                    f\"‚è≥ Early stopping: {patience_counter}/{early_stopping_patience}\"\n",
    "                )\n",
    "\n",
    "            # Early stopping\n",
    "            if patience_counter >= early_stopping_patience:\n",
    "                print(\"üõë –†–∞–Ω–Ω—è—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞!\")\n",
    "                break\n",
    "\n",
    "        print(\"\\n–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!\")\n",
    "        self.plot_training_history()\n",
    "\n",
    "    def evaluate(self):\n",
    "        \"\"\"–§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –Ω–∞–±–æ—Ä–µ\"\"\"\n",
    "        print(\"\\n–û—Ü–µ–Ω–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –Ω–∞–±–æ—Ä–µ...\")\n",
    "        self.model.eval()\n",
    "\n",
    "        total_correct = 0\n",
    "        total_from_correct = 0\n",
    "        total_to_correct = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for boards, from_targets, to_targets in tqdm(\n",
    "                self.test_loader, desc=\"Testing\"\n",
    "            ):\n",
    "                boards = boards.to(self.device)\n",
    "                from_targets = from_targets.cpu()\n",
    "                to_targets = to_targets.cpu()\n",
    "\n",
    "                # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥\n",
    "                policy_output = self.model(boards)\n",
    "\n",
    "                # –î–µ–∫–æ–¥–∏—Ä—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
    "                from_preds, to_preds, promo_preds = self._decode_policy_prediction(\n",
    "                    policy_output\n",
    "                )\n",
    "\n",
    "                # –ü–æ–¥—Å—á–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π\n",
    "                batch_size = boards.size(0)\n",
    "                total_samples += batch_size\n",
    "\n",
    "                # –ü–æ–ª–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å —Ö–æ–¥–∞\n",
    "                policy_flat = policy_output.view(policy_output.size(0), -1)\n",
    "                target_labels = self._policy_to_move_labels(\n",
    "                    policy_output,\n",
    "                    from_targets.to(self.device),\n",
    "                    to_targets.to(self.device),\n",
    "                )\n",
    "                preds = torch.argmax(policy_flat, dim=1)\n",
    "                correct = (preds == target_labels).sum().item()\n",
    "                total_correct += correct\n",
    "\n",
    "                # –¢–æ—á–Ω–æ—Å—Ç—å –¥–ª—è from-square\n",
    "                from_correct = (from_preds == from_targets).sum().item()\n",
    "                total_from_correct += from_correct\n",
    "\n",
    "                # –¢–æ—á–Ω–æ—Å—Ç—å –¥–ª—è to-square (—É—á–∏—Ç—ã–≤–∞—è –ø—Ä–µ–≤—Ä–∞—â–µ–Ω–∏—è)\n",
    "                to_correct = (to_preds == to_targets).sum().item()\n",
    "                total_to_correct += to_correct\n",
    "\n",
    "        full_acc = total_correct / total_samples\n",
    "        from_acc = total_from_correct / total_samples\n",
    "        to_acc = total_to_correct / total_samples\n",
    "\n",
    "        print(f\"\\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –Ω–∞–±–æ—Ä–µ:\")\n",
    "        print(f\"Full Move Accuracy: {full_acc:.4f}\")\n",
    "        print(f\"From-square Accuracy: {from_acc:.4f}\")\n",
    "        print(f\"To-square Accuracy: {to_acc:.4f}\")\n",
    "\n",
    "        return full_acc, from_acc, to_acc\n",
    "\n",
    "    def save_model(self, path):\n",
    "        \"\"\"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\"\"\"\n",
    "        torch.save(\n",
    "            {\n",
    "                \"model_state_dict\": self.model.state_dict(),\n",
    "                \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "                \"history\": self.history,\n",
    "            },\n",
    "            path,\n",
    "        )\n",
    "\n",
    "    def load_model(self, path):\n",
    "        \"\"\"–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏\"\"\"\n",
    "        checkpoint = torch.load(path, map_location=self.device)\n",
    "        self.model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        self.optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "        self.history = checkpoint[\"history\"]\n",
    "\n",
    "    def plot_training_history(self):\n",
    "        \"\"\"–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∏—Å—Ç–æ—Ä–∏–∏ –æ–±—É—á–µ–Ω–∏—è\"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "        # –ü–æ—Ç–µ—Ä–∏\n",
    "        ax1.plot(self.history[\"train_loss\"], label=\"Train Loss\")\n",
    "        ax1.plot(self.history[\"val_loss\"], label=\"Val Loss\")\n",
    "        ax1.set_title(\"–ü–æ—Ç–µ—Ä–∏\")\n",
    "        ax1.set_xlabel(\"–≠–ø–æ—Ö–∞\")\n",
    "        ax1.set_ylabel(\"Loss\")\n",
    "        ax1.legend()\n",
    "        ax1.grid(True)\n",
    "\n",
    "        # –¢–æ—á–Ω–æ—Å—Ç—å\n",
    "        ax2.plot(self.history[\"train_accuracy\"], label=\"Train Accuracy\")\n",
    "        ax2.plot(self.history[\"val_accuracy\"], label=\"Val Accuracy\")\n",
    "        ax2.set_title(\"–¢–æ—á–Ω–æ—Å—Ç—å\")\n",
    "        ax2.set_xlabel(\"–≠–ø–æ—Ö–∞\")\n",
    "        ax2.set_ylabel(\"Accuracy\")\n",
    "        ax2.legend()\n",
    "        ax2.grid(True)\n",
    "\n",
    "        # Learning rate\n",
    "        ax3.plot(self.history[\"learning_rate\"])\n",
    "        ax3.set_title(\"Learning Rate\")\n",
    "        ax3.set_xlabel(\"–≠–ø–æ—Ö–∞\")\n",
    "        ax3.set_ylabel(\"LR\")\n",
    "        ax3.grid(True)\n",
    "\n",
    "        # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –ø–æ—Ç–µ—Ä—å\n",
    "        ax4.plot(self.history[\"train_loss\"], label=\"Train Loss\", alpha=0.7)\n",
    "        ax4.plot(self.history[\"val_loss\"], label=\"Val Loss\", alpha=0.7)\n",
    "        ax4.set_title(\"–ü–æ—Ç–µ—Ä–∏ (–ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–∞—è —à–∫–∞–ª–∞)\")\n",
    "        ax4.set_xlabel(\"–≠–ø–æ—Ö–∞\")\n",
    "        ax4.set_ylabel(\"Loss\")\n",
    "        ax4.set_yscale(\"log\")\n",
    "        ax4.legend()\n",
    "        ax4.grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"training_history_resnet.png\", dpi=300, bbox_inches=\"tight\")\n",
    "        plt.show()\n",
    "\n",
    "    def predict_move(self, fen):\n",
    "        \"\"\"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ö–æ–¥–∞ –¥–ª—è –æ–¥–Ω–æ–π –ø–æ–∑–∏—Ü–∏–∏\"\"\"\n",
    "        self.model.eval()\n",
    "\n",
    "        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ FEN –≤ tensor\n",
    "        board_tensor = self._fen_to_tensor(fen).unsqueeze(0).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            policy_output = self.model(board_tensor)  # [1, 73, 64]\n",
    "            from_pred, to_pred, promotion = self._decode_policy_prediction(\n",
    "                policy_output\n",
    "            )\n",
    "\n",
    "        return from_pred[0].item(), to_pred[0].item(), promotion[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47564f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}\")\n",
    "\n",
    "    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "    print(\"–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...\")\n",
    "    splitter = ChessDataSplitter(\n",
    "        test_ratio=0.01,\n",
    "        val_ratio=0.2 * (1 - 0.01),\n",
    "        train_ratio=0.8 * (1 - 0.01),\n",
    "        csv_file=\"fens_training_set.csv\",\n",
    "    )\n",
    "    train_dataset, val_dataset, test_dataset = splitter.split_data()\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "    # –ú–æ–¥–µ–ª—å\n",
    "    print(\"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏...\")\n",
    "    model = ChessResNetWithAttention()\n",
    "\n",
    "    # –¢—Ä–µ–Ω–µ—Ä\n",
    "    trainer = ChessTrainer(model, train_loader, val_loader, test_loader, device)\n",
    "\n",
    "    # –û–±—É—á–µ–Ω–∏–µ\n",
    "    trainer.train(num_epochs=20, early_stopping_patience=10)\n",
    "\n",
    "    # –í–∞–ª–∏–¥–∞—Ü–∏—è\n",
    "    trainer.validate()\n",
    "\n",
    "    # # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏\n",
    "    # trainer.save_model(\"final_chess_model.pth\")\n",
    "    # print(\"–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79bfaaea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: cpu\n",
      "–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...\n",
      "0.792 0.198 0.01\n",
      "–ó–∞–≥—Ä—É–∂–µ–Ω–æ 268549 –≤–∞–ª–∏–¥–Ω—ã—Ö –ø–æ–∑–∏—Ü–∏–π\n",
      "–†–∞–∑–±–∏–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ:\n",
      "Train: 212690 samples (79.2%)\n",
      "Val: 53173 samples (19.8%)\n",
      "Test: 2686 samples (1.0%)\n",
      "–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏...\n",
      "–ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è ResNet –º–æ–¥–µ–ª–∏...\n",
      "–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: cpu\n",
      "–†–∞–∑–º–µ—Ä —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞: 212690\n",
      "–†–∞–∑–º–µ—Ä –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞: 53173\n",
      "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤: 4672\n",
      "\n",
      "–≠–ø–æ—Ö–∞ 1/20\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|‚ñè         | 127/6647 [00:27<23:21,  4.65it/s, Loss=8.0598, Accuracy=0.000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     23\u001b[39m trainer = ChessTrainer(model, train_loader, val_loader, test_loader, device)\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# –û–±—É—á–µ–Ω–∏–µ\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_patience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# –í–∞–ª–∏–¥–∞—Ü–∏—è\u001b[39;00m\n\u001b[32m     29\u001b[39m trainer.validate()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 222\u001b[39m, in \u001b[36mChessTrainer.train\u001b[39m\u001b[34m(self, num_epochs, early_stopping_patience)\u001b[39m\n\u001b[32m    219\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m50\u001b[39m)\n\u001b[32m    221\u001b[39m \u001b[38;5;66;03m# –û–±—É—á–µ–Ω–∏–µ\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m train_loss, train_acc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[38;5;66;03m# –í–∞–ª–∏–¥–∞—Ü–∏—è\u001b[39;00m\n\u001b[32m    225\u001b[39m val_loss, val_acc = \u001b[38;5;28mself\u001b[39m.validate()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 119\u001b[39m, in \u001b[36mChessTrainer.train_epoch\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;28mself\u001b[39m.optimizer.zero_grad()\n\u001b[32m    118\u001b[39m \u001b[38;5;66;03m# –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m policy_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mboards\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch, 69, 64]\u001b[39;00m\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º policy output –≤ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è loss\u001b[39;00m\n\u001b[32m    122\u001b[39m policy_flat = policy_output.view(policy_output.size(\u001b[32m0\u001b[39m), -\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# [batch, 4672]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/—É–Ω–∏–≤–µ—Ä/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/—É–Ω–∏–≤–µ—Ä/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mChessResNetWithAttention.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     35\u001b[39m     \u001b[38;5;66;03m# Feature extraction\u001b[39;00m\n\u001b[32m     36\u001b[39m     x = F.relu(\u001b[38;5;28mself\u001b[39m.bn_input(\u001b[38;5;28mself\u001b[39m.conv_input(x)))\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mres_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# Spatial attention\u001b[39;00m\n\u001b[32m     40\u001b[39m     attention_weights = F.softmax(\n\u001b[32m     41\u001b[39m         \u001b[38;5;28mself\u001b[39m.attention_conv(x).view(x.size(\u001b[32m0\u001b[39m), -\u001b[32m1\u001b[39m), dim=\u001b[32m1\u001b[39m\n\u001b[32m     42\u001b[39m     ).view(x.size(\u001b[32m0\u001b[39m), \u001b[32m1\u001b[39m, \u001b[32m8\u001b[39m, \u001b[32m8\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/—É–Ω–∏–≤–µ—Ä/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/—É–Ω–∏–≤–µ—Ä/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/—É–Ω–∏–≤–µ—Ä/.venv/lib/python3.13/site-packages/torch/nn/modules/container.py:244\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    243\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/—É–Ω–∏–≤–µ—Ä/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/—É–Ω–∏–≤–µ—Ä/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mResidualBlock.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     10\u001b[39m     residual = x\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     x = F.relu(\u001b[38;5;28mself\u001b[39m.bn1(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[32m     12\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.bn2(\u001b[38;5;28mself\u001b[39m.conv2(x))\n\u001b[32m     13\u001b[39m     x += residual\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/—É–Ω–∏–≤–µ—Ä/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/—É–Ω–∏–≤–µ—Ä/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/—É–Ω–∏–≤–µ—Ä/.venv/lib/python3.13/site-packages/torch/nn/modules/conv.py:548\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    547\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m548\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/—É–Ω–∏–≤–µ—Ä/.venv/lib/python3.13/site-packages/torch/nn/modules/conv.py:543\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    533\u001b[39m         F.pad(\n\u001b[32m    534\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    541\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    542\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m543\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    544\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    545\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a62c66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
