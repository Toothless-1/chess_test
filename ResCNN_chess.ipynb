{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "459ef6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from typing import List, Tuple\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "seed = 123456\n",
    "np.random.seed(seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215217a3",
   "metadata": {},
   "source": [
    "# Разработка модели\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "731c677a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualHeadChessDataset(Dataset):\n",
    "    def __init__(self, csv_file: str):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "\n",
    "        self._validate_data()\n",
    "        self.piece_to_idx = {\n",
    "            \"P\": 0,\n",
    "            \"N\": 1,\n",
    "            \"B\": 2,\n",
    "            \"R\": 3,\n",
    "            \"Q\": 4,\n",
    "            \"K\": 5,\n",
    "            \"p\": 6,\n",
    "            \"n\": 7,\n",
    "            \"b\": 8,\n",
    "            \"r\": 9,\n",
    "            \"q\": 10,\n",
    "            \"k\": 11,\n",
    "        }\n",
    "\n",
    "    def _validate_data(self):\n",
    "        valid_indices = []\n",
    "        for idx, row in self.df.iterrows():\n",
    "            try:\n",
    "                board = chess.Board(row[\"fen\"])\n",
    "                move = chess.Move.from_uci(row[\"move\"])\n",
    "                if move in board.legal_moves:\n",
    "                    valid_indices.append(idx)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        self.df = self.df.loc[valid_indices].reset_index(drop=True)\n",
    "        print(f\"Загружено {len(self.df)} валидных позиций\")\n",
    "\n",
    "    def _board_to_tensor(self, fen: str) -> torch.Tensor:\n",
    "        board = chess.Board(fen)\n",
    "        tensor = torch.zeros(20, 8, 8, dtype=torch.float32)\n",
    "\n",
    "        # Фигуры (плоскости 0-11)\n",
    "        for square in chess.SQUARES:\n",
    "            piece = board.piece_at(square)\n",
    "            if piece:\n",
    "                row, col = square // 8, square % 8\n",
    "                piece_idx = self.piece_to_idx[piece.symbol()]\n",
    "                tensor[piece_idx, row, col] = 1.0\n",
    "\n",
    "        # Чей ход (плоскость 12)\n",
    "        tensor[12] = 1.0 if board.turn else 0.0\n",
    "\n",
    "        # Рокировки (плоскости 13-16)\n",
    "        castling_rights = [\n",
    "            board.has_kingside_castling_rights(chess.WHITE),\n",
    "            board.has_queenside_castling_rights(chess.WHITE),\n",
    "            board.has_kingside_castling_rights(chess.BLACK),\n",
    "            board.has_queenside_castling_rights(chess.BLACK),\n",
    "        ]\n",
    "        for i, has_right in enumerate(castling_rights):\n",
    "            if has_right:\n",
    "                tensor[13 + i] = 1.0\n",
    "\n",
    "        # Взятие на проходе (плоскость 17)\n",
    "        if board.ep_square is not None:\n",
    "            row, col = board.ep_square // 8, board.ep_square % 8\n",
    "            tensor[17, row, col] = 1.0\n",
    "\n",
    "        # Счетчик полуходов (плоскость 18)\n",
    "        tensor[18] = board.halfmove_clock / 50.0\n",
    "\n",
    "        # Номер хода (плоскость 19)\n",
    "        tensor[19] = board.fullmove_number / 500.0\n",
    "\n",
    "        return tensor\n",
    "\n",
    "    def _move_to_dual_labels(self, move_uci: str, fen: str) -> tuple:\n",
    "        board = chess.Board(fen)\n",
    "        move = chess.Move.from_uci(move_uci)\n",
    "\n",
    "        from_square = move.from_square\n",
    "\n",
    "        # Для to_square учитываем превращения\n",
    "        # ДИАПАЗОН ДОЛЖЕН БЫТЬ 0-68 (69 классов)\n",
    "        # print(move.promotion)\n",
    "        if move.promotion:\n",
    "            # Кодируем превращения: 64-68\n",
    "            to_square = 64 + (move.promotion - 1)  # 64, 65, 66, 67, 68\n",
    "        else:\n",
    "            to_square = move.to_square  # 0-63\n",
    "\n",
    "        # Проверяем, что to_square в правильном диапазоне\n",
    "        if to_square >= 69:\n",
    "            raise ValueError(f\"Некорректный to_square: {to_square} для хода {move_uci}\")\n",
    "\n",
    "        return from_square, to_square\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        fen = row[\"fen\"]\n",
    "        move = row[\"move\"]\n",
    "\n",
    "        board_tensor = self._board_to_tensor(fen)\n",
    "        from_label, to_label = self._move_to_dual_labels(move, fen)\n",
    "\n",
    "        return board_tensor, from_label, to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d81e9b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessDataSplitter:\n",
    "    def __init__(\n",
    "        self,\n",
    "        csv_file,\n",
    "        train_ratio=0.7,\n",
    "        val_ratio=0.15,\n",
    "        test_ratio=0.15,\n",
    "        random_state=42,\n",
    "    ):\n",
    "        print(train_ratio, val_ratio, test_ratio)\n",
    "        assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6, (\n",
    "            \"Сумма долей должна быть равна 1\"\n",
    "        )\n",
    "\n",
    "        self.csv_file = csv_file\n",
    "        self.train_ratio = train_ratio\n",
    "        self.val_ratio = val_ratio\n",
    "        self.test_ratio = test_ratio\n",
    "        self.random_state = random_state\n",
    "\n",
    "        # Загружаем полный dataset\n",
    "        self.full_dataset = DualHeadChessDataset(csv_file)\n",
    "\n",
    "    def split_data(self):\n",
    "        \"\"\"Разбивает данные на train/val/test\"\"\"\n",
    "        # Получаем индексы\n",
    "        n_total = len(self.full_dataset)\n",
    "        indices = list(range(n_total))\n",
    "\n",
    "        # Первое разбиение: отделяем test\n",
    "        train_val_idx, test_idx = train_test_split(\n",
    "            indices,\n",
    "            test_size=self.test_ratio,\n",
    "            random_state=self.random_state,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "        # Второе разбиение: разделяем train и val\n",
    "        train_idx, val_idx = train_test_split(\n",
    "            train_val_idx,\n",
    "            test_size=self.val_ratio / (self.train_ratio + self.val_ratio),\n",
    "            random_state=self.random_state,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "        # Создаем Subset datasets\n",
    "        train_dataset = Subset(self.full_dataset, train_idx)\n",
    "        val_dataset = Subset(self.full_dataset, val_idx)\n",
    "        test_dataset = Subset(self.full_dataset, test_idx)\n",
    "\n",
    "        print(f\"Разбиение завершено:\")\n",
    "        print(\n",
    "            f\"Train: {len(train_dataset)} samples ({len(train_dataset) / n_total * 100:.1f}%)\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Val: {len(val_dataset)} samples ({len(val_dataset) / n_total * 100:.1f}%)\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Test: {len(test_dataset)} samples ({len(test_dataset) / n_total * 100:.1f}%)\"\n",
    "        )\n",
    "\n",
    "        return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d1ed00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(channels, channels, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(channels, channels, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(channels)\n",
    "        self.bn2 = nn.BatchNorm2d(channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x += residual\n",
    "        return F.relu(x)\n",
    "\n",
    "\n",
    "class ChessResNetWithAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initial convolution\n",
    "        self.conv_input = nn.Conv2d(20, 256, 3, padding=1)\n",
    "        self.bn_input = nn.BatchNorm2d(256)\n",
    "\n",
    "        # Residual blocks\n",
    "        self.res_blocks = nn.Sequential(*[ResidualBlock(256) for _ in range(5)])\n",
    "\n",
    "        # Attention mechanism\n",
    "        self.attention_conv = nn.Conv2d(256, 1, 1)\n",
    "\n",
    "        # Policy head\n",
    "        self.policy_conv = nn.Conv2d(256, 69, 1)  # 64 moves + 5 promotions\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Feature extraction\n",
    "        x = F.relu(self.bn_input(self.conv_input(x)))\n",
    "        x = self.res_blocks(x)\n",
    "\n",
    "        # Spatial attention\n",
    "        attention_weights = F.softmax(\n",
    "            self.attention_conv(x).view(x.size(0), -1), dim=1\n",
    "        ).view(x.size(0), 1, 8, 8)\n",
    "\n",
    "        # Apply attention\n",
    "        x_attended = x * attention_weights\n",
    "\n",
    "        # Policy head\n",
    "        policy = self.policy_conv(x_attended)\n",
    "        policy = policy.view(policy.size(0), 69, 64)  # [batch, move_types, squares]\n",
    "\n",
    "        return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9842fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessTrainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        test_loader,\n",
    "        device=\"cpu\",\n",
    "        lr=0.01,\n",
    "        weight_decay=0.1,\n",
    "    ):\n",
    "        self.model = model.to(device)\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.device = device\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "\n",
    "        # Функция потерь для policy head\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Оптимизатор\n",
    "        self.optimizer = optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=self.lr,  # Уменьшил learning rate для стабильности\n",
    "            weight_decay=self.weight_decay,\n",
    "        )\n",
    "\n",
    "        # Планировщик learning rate\n",
    "        self.scheduler = optim.lr_scheduler.StepLR(\n",
    "            self.optimizer, step_size=5, gamma=3 * self.lr\n",
    "        )\n",
    "\n",
    "        # История обучения\n",
    "        self.history = {\n",
    "            \"train_loss\": [],\n",
    "            \"val_loss\": [],\n",
    "            \"train_accuracy\": [],\n",
    "            \"val_accuracy\": [],\n",
    "            \"learning_rate\": [],\n",
    "        }\n",
    "\n",
    "    def _policy_to_move_labels(self, policy_output, from_targets, to_targets):\n",
    "        \"\"\"\n",
    "        Преобразует policy output [batch, 69, 64] в метки ходов\n",
    "        и сравнивает с целевыми метками\n",
    "        \"\"\"\n",
    "        batch_size = policy_output.size(0)\n",
    "\n",
    "        # Создаем целевые метки в формате [batch, 4672]\n",
    "        target_labels = []\n",
    "        for i in range(batch_size):\n",
    "            from_sq = from_targets[i].item()\n",
    "            to_sq = to_targets[i].item()\n",
    "\n",
    "            # Определяем тип хода\n",
    "            if to_sq >= 64:\n",
    "                # Ход с превращением\n",
    "                promotion_type = to_sq - 64  # 0-3\n",
    "                move_label = from_sq * 69 + (64 + promotion_type)\n",
    "            else:\n",
    "                # Обычный ход\n",
    "                move_label = from_sq * 69 + to_sq\n",
    "\n",
    "            target_labels.append(move_label)\n",
    "\n",
    "        return torch.tensor(target_labels, device=self.device)\n",
    "\n",
    "    def _decode_policy_prediction(self, policy_output):\n",
    "        \"\"\"\n",
    "        Декодирует policy output в предсказанные from_square и to_square\n",
    "        \"\"\"\n",
    "        batch_size = policy_output.size(0)\n",
    "\n",
    "        # Reshape to [batch, 4672]\n",
    "        policy_flat = policy_output.view(batch_size, -1)\n",
    "\n",
    "        # Находим наиболее вероятный ход\n",
    "        move_preds = torch.argmax(policy_flat, dim=1)\n",
    "\n",
    "        from_preds = move_preds // 73\n",
    "        move_type = move_preds % 73\n",
    "\n",
    "        # Определяем to_square и promotion\n",
    "        to_preds = []\n",
    "        promo_preds = []\n",
    "        for move_type_val in move_type:\n",
    "            if move_type_val >= 64:\n",
    "                # Ход с превращением\n",
    "                to_preds.append(move_type_val - 64)  # to_square для превращений\n",
    "                promo_preds.append(move_type_val - 63)  # 1=queen, 2=rook, etc.\n",
    "            else:\n",
    "                # Обычный ход\n",
    "                to_preds.append(move_type_val)\n",
    "                promo_preds.append(0)\n",
    "\n",
    "        return (from_preds.cpu(), torch.tensor(to_preds), torch.tensor(promo_preds))\n",
    "\n",
    "    def train_epoch(self):\n",
    "        \"\"\"Одна эпоха обучения\"\"\"\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        train_bar = tqdm(self.train_loader, desc=\"Training\")\n",
    "\n",
    "        for batch_idx, (boards, from_targets, to_targets) in enumerate(train_bar):\n",
    "            # Перемещаем данные на device\n",
    "            boards = boards.to(self.device)\n",
    "            from_targets = from_targets.to(self.device)\n",
    "            to_targets = to_targets.to(self.device)\n",
    "\n",
    "            # Обнуляем градиенты\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            # Прямой проход\n",
    "            policy_output = self.model(boards)  # [batch, 69, 64]\n",
    "\n",
    "            # Преобразуем policy output в формат для loss\n",
    "            policy_flat = policy_output.view(policy_output.size(0), -1)  # [batch, 4672]\n",
    "\n",
    "            # Создаем целевые метки\n",
    "            target_labels = self._policy_to_move_labels(\n",
    "                policy_output, from_targets, to_targets\n",
    "            )\n",
    "\n",
    "            # Вычисляем потери\n",
    "            loss = self.criterion(policy_flat, target_labels)\n",
    "\n",
    "            # Обратный проход\n",
    "            loss.backward()\n",
    "\n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "\n",
    "            # Шаг оптимизатора\n",
    "            self.optimizer.step()\n",
    "\n",
    "            # Статистика\n",
    "            total_loss += loss.item()\n",
    "            batch_size = boards.size(0)\n",
    "            total_samples += batch_size\n",
    "\n",
    "            # Точность\n",
    "            preds = torch.argmax(policy_flat, dim=1)\n",
    "            correct = (preds == target_labels).sum().item()\n",
    "            total_correct += correct\n",
    "\n",
    "            # Обновляем progress bar\n",
    "            train_bar.set_postfix(\n",
    "                {\n",
    "                    \"Loss\": f\"{loss.item():.4f}\",\n",
    "                    \"Accuracy\": f\"{correct / batch_size:.3f}\",\n",
    "                }\n",
    "            )\n",
    "\n",
    "        # Вычисляем средние метрики за эпоху\n",
    "        avg_loss = total_loss / len(self.train_loader)\n",
    "        accuracy = total_correct / total_samples\n",
    "\n",
    "        return avg_loss, accuracy\n",
    "\n",
    "    def validate(self):\n",
    "        \"\"\"Валидация модели\"\"\"\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for boards, from_targets, to_targets in tqdm(\n",
    "                self.val_loader, desc=\"Validation\"\n",
    "            ):\n",
    "                boards = boards.to(self.device)\n",
    "                from_targets = from_targets.to(self.device)\n",
    "                to_targets = to_targets.to(self.device)\n",
    "\n",
    "                # Прямой проход\n",
    "                policy_output = self.model(boards)\n",
    "                policy_flat = policy_output.view(policy_output.size(0), -1)\n",
    "\n",
    "                # Целевые метки\n",
    "                target_labels = self._policy_to_move_labels(\n",
    "                    policy_output, from_targets, to_targets\n",
    "                )\n",
    "\n",
    "                # Потери\n",
    "                loss = self.criterion(policy_flat, target_labels)\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                batch_size = boards.size(0)\n",
    "                total_samples += batch_size\n",
    "\n",
    "                # Точность\n",
    "                preds = torch.argmax(policy_flat, dim=1)\n",
    "                correct = (preds == target_labels).sum().item()\n",
    "                total_correct += correct\n",
    "\n",
    "        avg_loss = total_loss / len(self.val_loader)\n",
    "        accuracy = total_correct / total_samples\n",
    "\n",
    "        return avg_loss, accuracy\n",
    "\n",
    "    def train(self, num_epochs=50, early_stopping_patience=10):\n",
    "        \"\"\"Полный цикл обучения\"\"\"\n",
    "        best_val_loss = float(\"inf\")\n",
    "        patience_counter = 0\n",
    "\n",
    "        print(\"Начало обучения ResNet модели...\")\n",
    "        print(f\"Используется устройство: {self.device}\")\n",
    "        print(f\"Размер тренировочного набора: {len(self.train_loader.dataset)}\")\n",
    "        print(f\"Размер валидационного набора: {len(self.val_loader.dataset)}\")\n",
    "        print(f\"Количество классов: 4672\")\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f\"\\nЭпоха {epoch + 1}/{num_epochs}\")\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "            # Обучение\n",
    "            train_loss, train_acc = self.train_epoch()\n",
    "\n",
    "            # Валидация\n",
    "            val_loss, val_acc = self.validate()\n",
    "\n",
    "            # Обновление learning rate\n",
    "            self.scheduler.step(val_loss)\n",
    "            current_lr = self.optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "            # Сохраняем историю\n",
    "            self.history[\"train_loss\"].append(train_loss)\n",
    "            self.history[\"val_loss\"].append(val_loss)\n",
    "            self.history[\"train_accuracy\"].append(train_acc)\n",
    "            self.history[\"val_accuracy\"].append(val_acc)\n",
    "            self.history[\"learning_rate\"].append(current_lr)\n",
    "\n",
    "            # Выводим результаты\n",
    "            print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "            print(f\"Train Accuracy: {train_acc:.4f} | Val Accuracy: {val_acc:.4f}\")\n",
    "            print(f\"Learning Rate: {current_lr:.6f}\")\n",
    "\n",
    "            # Сохранение лучшей модели\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                patience_counter = 0\n",
    "                self.save_model(\"best_chess_resnet_model.pth\")\n",
    "                print(\"✅ Сохранена лучшая модель!\")\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                print(\n",
    "                    f\"⏳ Early stopping: {patience_counter}/{early_stopping_patience}\"\n",
    "                )\n",
    "\n",
    "            # Early stopping\n",
    "            if patience_counter >= early_stopping_patience:\n",
    "                print(\"🛑 Ранняя остановка!\")\n",
    "                break\n",
    "\n",
    "        print(\"\\nОбучение завершено!\")\n",
    "        self.plot_training_history()\n",
    "\n",
    "    def evaluate(self):\n",
    "        \"\"\"Финальная оценка на тестовом наборе\"\"\"\n",
    "        print(\"\\nОценка на тестовом наборе...\")\n",
    "        self.model.eval()\n",
    "\n",
    "        total_correct = 0\n",
    "        total_from_correct = 0\n",
    "        total_to_correct = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for boards, from_targets, to_targets in tqdm(\n",
    "                self.test_loader, desc=\"Testing\"\n",
    "            ):\n",
    "                boards = boards.to(self.device)\n",
    "                from_targets = from_targets.cpu()\n",
    "                to_targets = to_targets.cpu()\n",
    "\n",
    "                # Прямой проход\n",
    "                policy_output = self.model(boards)\n",
    "\n",
    "                # Декодируем предсказания\n",
    "                from_preds, to_preds, promo_preds = self._decode_policy_prediction(\n",
    "                    policy_output\n",
    "                )\n",
    "\n",
    "                # Подсчет правильных предсказаний\n",
    "                batch_size = boards.size(0)\n",
    "                total_samples += batch_size\n",
    "\n",
    "                # Полная точность хода\n",
    "                policy_flat = policy_output.view(policy_output.size(0), -1)\n",
    "                target_labels = self._policy_to_move_labels(\n",
    "                    policy_output,\n",
    "                    from_targets.to(self.device),\n",
    "                    to_targets.to(self.device),\n",
    "                )\n",
    "                preds = torch.argmax(policy_flat, dim=1)\n",
    "                correct = (preds == target_labels).sum().item()\n",
    "                total_correct += correct\n",
    "\n",
    "                # Точность для from-square\n",
    "                from_correct = (from_preds == from_targets).sum().item()\n",
    "                total_from_correct += from_correct\n",
    "\n",
    "                # Точность для to-square (учитывая превращения)\n",
    "                to_correct = (to_preds == to_targets).sum().item()\n",
    "                total_to_correct += to_correct\n",
    "\n",
    "        full_acc = total_correct / total_samples\n",
    "        from_acc = total_from_correct / total_samples\n",
    "        to_acc = total_to_correct / total_samples\n",
    "\n",
    "        print(f\"\\nРезультаты на тестовом наборе:\")\n",
    "        print(f\"Full Move Accuracy: {full_acc:.4f}\")\n",
    "        print(f\"From-square Accuracy: {from_acc:.4f}\")\n",
    "        print(f\"To-square Accuracy: {to_acc:.4f}\")\n",
    "\n",
    "        return full_acc, from_acc, to_acc\n",
    "\n",
    "    def save_model(self, path):\n",
    "        \"\"\"Сохранение модели\"\"\"\n",
    "        torch.save(\n",
    "            {\n",
    "                \"model_state_dict\": self.model.state_dict(),\n",
    "                \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "                \"history\": self.history,\n",
    "            },\n",
    "            path,\n",
    "        )\n",
    "\n",
    "    def load_model(self, path):\n",
    "        \"\"\"Загрузка модели\"\"\"\n",
    "        checkpoint = torch.load(path, map_location=self.device)\n",
    "        self.model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        self.optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "        self.history = checkpoint[\"history\"]\n",
    "\n",
    "    def plot_training_history(self):\n",
    "        \"\"\"Визуализация истории обучения\"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "        # Потери\n",
    "        ax1.plot(self.history[\"train_loss\"], label=\"Train Loss\")\n",
    "        ax1.plot(self.history[\"val_loss\"], label=\"Val Loss\")\n",
    "        ax1.set_title(\"Потери\")\n",
    "        ax1.set_xlabel(\"Эпоха\")\n",
    "        ax1.set_ylabel(\"Loss\")\n",
    "        ax1.legend()\n",
    "        ax1.grid(True)\n",
    "\n",
    "        # Точность\n",
    "        ax2.plot(self.history[\"train_accuracy\"], label=\"Train Accuracy\")\n",
    "        ax2.plot(self.history[\"val_accuracy\"], label=\"Val Accuracy\")\n",
    "        ax2.set_title(\"Точность\")\n",
    "        ax2.set_xlabel(\"Эпоха\")\n",
    "        ax2.set_ylabel(\"Accuracy\")\n",
    "        ax2.legend()\n",
    "        ax2.grid(True)\n",
    "\n",
    "        # Learning rate\n",
    "        ax3.plot(self.history[\"learning_rate\"])\n",
    "        ax3.set_title(\"Learning Rate\")\n",
    "        ax3.set_xlabel(\"Эпоха\")\n",
    "        ax3.set_ylabel(\"LR\")\n",
    "        ax3.grid(True)\n",
    "\n",
    "        # Соотношение потерь\n",
    "        ax4.plot(self.history[\"train_loss\"], label=\"Train Loss\", alpha=0.7)\n",
    "        ax4.plot(self.history[\"val_loss\"], label=\"Val Loss\", alpha=0.7)\n",
    "        ax4.set_title(\"Потери (логарифмическая шкала)\")\n",
    "        ax4.set_xlabel(\"Эпоха\")\n",
    "        ax4.set_ylabel(\"Loss\")\n",
    "        ax4.set_yscale(\"log\")\n",
    "        ax4.legend()\n",
    "        ax4.grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"training_history_resnet.png\", dpi=300, bbox_inches=\"tight\")\n",
    "        plt.show()\n",
    "\n",
    "    def predict_move(self, fen):\n",
    "        \"\"\"Предсказание хода для одной позиции\"\"\"\n",
    "        self.model.eval()\n",
    "\n",
    "        # Преобразование FEN в tensor\n",
    "        board_tensor = self._fen_to_tensor(fen).unsqueeze(0).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            policy_output = self.model(board_tensor)  # [1, 73, 64]\n",
    "            from_pred, to_pred, promotion = self._decode_policy_prediction(\n",
    "                policy_output\n",
    "            )\n",
    "\n",
    "        return from_pred[0].item(), to_pred[0].item(), promotion[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47564f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Используется устройство: {device}\")\n",
    "\n",
    "    # Загрузка данных\n",
    "    print(\"Загрузка данных...\")\n",
    "    splitter = ChessDataSplitter(\n",
    "        test_ratio=0.01,\n",
    "        val_ratio=0.2 * (1 - 0.01),\n",
    "        train_ratio=0.8 * (1 - 0.01),\n",
    "        csv_file=\"fens_training_set.csv\",\n",
    "    )\n",
    "    train_dataset, val_dataset, test_dataset = splitter.split_data()\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "    # Модель\n",
    "    print(\"Инициализация модели...\")\n",
    "    model = ChessResNetWithAttention()\n",
    "\n",
    "    # Тренер\n",
    "    trainer = ChessTrainer(model, train_loader, val_loader, test_loader, device)\n",
    "\n",
    "    # Обучение\n",
    "    trainer.train(num_epochs=20, early_stopping_patience=10)\n",
    "\n",
    "    # Валидация\n",
    "    trainer.validate()\n",
    "\n",
    "    # # Сохранение финальной модели\n",
    "    # trainer.save_model(\"final_chess_model.pth\")\n",
    "    # print(\"Модель сохранена!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79bfaaea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используется устройство: cpu\n",
      "Загрузка данных...\n",
      "0.792 0.198 0.01\n",
      "Загружено 268549 валидных позиций\n",
      "Разбиение завершено:\n",
      "Train: 212690 samples (79.2%)\n",
      "Val: 53173 samples (19.8%)\n",
      "Test: 2686 samples (1.0%)\n",
      "Инициализация модели...\n",
      "Начало обучения ResNet модели...\n",
      "Используется устройство: cpu\n",
      "Размер тренировочного набора: 212690\n",
      "Размер валидационного набора: 53173\n",
      "Количество классов: 4672\n",
      "\n",
      "Эпоха 1/20\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 127/6647 [00:27<23:21,  4.65it/s, Loss=8.0598, Accuracy=0.000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     23\u001b[39m trainer = ChessTrainer(model, train_loader, val_loader, test_loader, device)\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Обучение\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_patience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Валидация\u001b[39;00m\n\u001b[32m     29\u001b[39m trainer.validate()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 222\u001b[39m, in \u001b[36mChessTrainer.train\u001b[39m\u001b[34m(self, num_epochs, early_stopping_patience)\u001b[39m\n\u001b[32m    219\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m50\u001b[39m)\n\u001b[32m    221\u001b[39m \u001b[38;5;66;03m# Обучение\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m train_loss, train_acc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[38;5;66;03m# Валидация\u001b[39;00m\n\u001b[32m    225\u001b[39m val_loss, val_acc = \u001b[38;5;28mself\u001b[39m.validate()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 119\u001b[39m, in \u001b[36mChessTrainer.train_epoch\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;28mself\u001b[39m.optimizer.zero_grad()\n\u001b[32m    118\u001b[39m \u001b[38;5;66;03m# Прямой проход\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m policy_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mboards\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch, 69, 64]\u001b[39;00m\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# Преобразуем policy output в формат для loss\u001b[39;00m\n\u001b[32m    122\u001b[39m policy_flat = policy_output.view(policy_output.size(\u001b[32m0\u001b[39m), -\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# [batch, 4672]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/универ/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/универ/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mChessResNetWithAttention.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     35\u001b[39m     \u001b[38;5;66;03m# Feature extraction\u001b[39;00m\n\u001b[32m     36\u001b[39m     x = F.relu(\u001b[38;5;28mself\u001b[39m.bn_input(\u001b[38;5;28mself\u001b[39m.conv_input(x)))\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mres_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# Spatial attention\u001b[39;00m\n\u001b[32m     40\u001b[39m     attention_weights = F.softmax(\n\u001b[32m     41\u001b[39m         \u001b[38;5;28mself\u001b[39m.attention_conv(x).view(x.size(\u001b[32m0\u001b[39m), -\u001b[32m1\u001b[39m), dim=\u001b[32m1\u001b[39m\n\u001b[32m     42\u001b[39m     ).view(x.size(\u001b[32m0\u001b[39m), \u001b[32m1\u001b[39m, \u001b[32m8\u001b[39m, \u001b[32m8\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/универ/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/универ/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/универ/.venv/lib/python3.13/site-packages/torch/nn/modules/container.py:244\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    243\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/универ/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/универ/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mResidualBlock.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     10\u001b[39m     residual = x\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     x = F.relu(\u001b[38;5;28mself\u001b[39m.bn1(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[32m     12\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.bn2(\u001b[38;5;28mself\u001b[39m.conv2(x))\n\u001b[32m     13\u001b[39m     x += residual\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/универ/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/универ/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/универ/.venv/lib/python3.13/site-packages/torch/nn/modules/conv.py:548\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    547\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m548\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/универ/.venv/lib/python3.13/site-packages/torch/nn/modules/conv.py:543\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    533\u001b[39m         F.pad(\n\u001b[32m    534\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    541\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    542\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m543\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    544\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    545\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a62c66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
