{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "459ef6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision.models import resnet50\n",
    "from typing import List, Tuple\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "seed = 123456\n",
    "np.random.seed(seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215217a3",
   "metadata": {},
   "source": [
    "# Разработка модели\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "731c677a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualHeadChessDataset(Dataset):\n",
    "    def __init__(self, csv_file: str):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "\n",
    "        self._validate_data()\n",
    "        self.piece_to_idx = {\n",
    "            \"P\": 0,\n",
    "            \"N\": 1,\n",
    "            \"B\": 2,\n",
    "            \"R\": 3,\n",
    "            \"Q\": 4,\n",
    "            \"K\": 5,\n",
    "            \"p\": 6,\n",
    "            \"n\": 7,\n",
    "            \"b\": 8,\n",
    "            \"r\": 9,\n",
    "            \"q\": 10,\n",
    "            \"k\": 11,\n",
    "        }\n",
    "\n",
    "    def _validate_data(self):\n",
    "        valid_indices = []\n",
    "        for idx, row in self.df.iterrows():\n",
    "            try:\n",
    "                board = chess.Board(row[\"fen\"])\n",
    "                move = chess.Move.from_uci(row[\"move\"])\n",
    "                if move in board.legal_moves:\n",
    "                    valid_indices.append(idx)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        self.df = self.df.loc[valid_indices].reset_index(drop=True)\n",
    "        print(f\"Загружено {len(self.df)} валидных позиций\")\n",
    "\n",
    "    def _board_to_tensor(self, fen: str) -> torch.Tensor:\n",
    "        board = chess.Board(fen)\n",
    "        tensor = torch.zeros(20, 8, 8, dtype=torch.float32)\n",
    "\n",
    "        # Фигуры (плоскости 0-11)\n",
    "        for square in chess.SQUARES:\n",
    "            piece = board.piece_at(square)\n",
    "            if piece:\n",
    "                row, col = square // 8, square % 8\n",
    "                piece_idx = self.piece_to_idx[piece.symbol()]\n",
    "                tensor[piece_idx, row, col] = 1.0\n",
    "\n",
    "        # Чей ход (плоскость 12)\n",
    "        tensor[12] = 1.0 if board.turn else 0.0\n",
    "\n",
    "        # Рокировки (плоскости 13-16)\n",
    "        castling_rights = [\n",
    "            board.has_kingside_castling_rights(chess.WHITE),\n",
    "            board.has_queenside_castling_rights(chess.WHITE),\n",
    "            board.has_kingside_castling_rights(chess.BLACK),\n",
    "            board.has_queenside_castling_rights(chess.BLACK),\n",
    "        ]\n",
    "        for i, has_right in enumerate(castling_rights):\n",
    "            if has_right:\n",
    "                tensor[13 + i] = 1.0\n",
    "\n",
    "        # Взятие на проходе (плоскость 17)\n",
    "        if board.ep_square is not None:\n",
    "            row, col = board.ep_square // 8, board.ep_square % 8\n",
    "            tensor[17, row, col] = 1.0\n",
    "\n",
    "        # Счетчик полуходов (плоскость 18)\n",
    "        tensor[18] = board.halfmove_clock / 50.0\n",
    "\n",
    "        # Номер хода (плоскость 19)\n",
    "        tensor[19] = board.fullmove_number / 500.0\n",
    "\n",
    "        return tensor\n",
    "\n",
    "    def _move_to_dual_labels(self, move_uci: str, fen: str) -> tuple:\n",
    "        board = chess.Board(fen)\n",
    "        move = chess.Move.from_uci(move_uci)\n",
    "\n",
    "        from_square = move.from_square\n",
    "\n",
    "        # Для to_square учитываем превращения\n",
    "        # ДИАПАЗОН ДОЛЖЕН БЫТЬ 0-68 (69 классов)\n",
    "        # print(move.promotion)\n",
    "        if move.promotion:\n",
    "            # Кодируем превращения: 64-68\n",
    "            to_square = 64 + (move.promotion - 1)  # 64, 65, 66, 67, 68\n",
    "        else:\n",
    "            to_square = move.to_square  # 0-63\n",
    "\n",
    "        # Проверяем, что to_square в правильном диапазоне\n",
    "        if to_square >= 69:\n",
    "            raise ValueError(f\"Некорректный to_square: {to_square} для хода {move_uci}\")\n",
    "\n",
    "        return from_square, to_square\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        fen = row[\"fen\"]\n",
    "        move = row[\"move\"]\n",
    "\n",
    "        board_tensor = self._board_to_tensor(fen)\n",
    "        from_label, to_label = self._move_to_dual_labels(move, fen)\n",
    "\n",
    "        return board_tensor, from_label, to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d81e9b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessDataSplitter:\n",
    "    def __init__(\n",
    "        self,\n",
    "        csv_file,\n",
    "        train_ratio=0.7,\n",
    "        val_ratio=0.15,\n",
    "        test_ratio=0.15,\n",
    "        random_state=42,\n",
    "    ):\n",
    "        print(train_ratio, val_ratio, test_ratio)\n",
    "        assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6, (\n",
    "            \"Сумма долей должна быть равна 1\"\n",
    "        )\n",
    "\n",
    "        self.csv_file = csv_file\n",
    "        self.train_ratio = train_ratio\n",
    "        self.val_ratio = val_ratio\n",
    "        self.test_ratio = test_ratio\n",
    "        self.random_state = random_state\n",
    "\n",
    "        # Загружаем полный dataset\n",
    "        self.full_dataset = DualHeadChessDataset(csv_file)\n",
    "\n",
    "    def split_data(self):\n",
    "        \"\"\"Разбивает данные на train/val/test\"\"\"\n",
    "        # Получаем индексы\n",
    "        n_total = len(self.full_dataset)\n",
    "        indices = list(range(n_total))\n",
    "\n",
    "        # Первое разбиение: отделяем test\n",
    "        train_val_idx, test_idx = train_test_split(\n",
    "            indices,\n",
    "            test_size=self.test_ratio,\n",
    "            random_state=self.random_state,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "        # Второе разбиение: разделяем train и val\n",
    "        train_idx, val_idx = train_test_split(\n",
    "            train_val_idx,\n",
    "            test_size=self.val_ratio / (self.train_ratio + self.val_ratio),\n",
    "            random_state=self.random_state,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "        # Создаем Subset datasets\n",
    "        train_dataset = Subset(self.full_dataset, train_idx)\n",
    "        val_dataset = Subset(self.full_dataset, val_idx)\n",
    "        test_dataset = Subset(self.full_dataset, test_idx)\n",
    "\n",
    "        print(f\"Разбиение завершено:\")\n",
    "        print(\n",
    "            f\"Train: {len(train_dataset)} samples ({len(train_dataset) / n_total * 100:.1f}%)\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Val: {len(val_dataset)} samples ({len(val_dataset) / n_total * 100:.1f}%)\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Test: {len(test_dataset)} samples ({len(test_dataset) / n_total * 100:.1f}%)\"\n",
    "        )\n",
    "\n",
    "        return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d1ed00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualCNNWithAttention(nn.Module):\n",
    "    def __init__(self, device=\"cpu\", pretrained=True):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "\n",
    "        # ResNet-50 backbone\n",
    "        self.backbone = resnet50(pretrained=pretrained)\n",
    "\n",
    "        # Модифицируем ResNet для работы с нашими данными\n",
    "        # 1. Заменяем первый слой для 20 каналов (входные плоскости шахматной доски)\n",
    "        original_first_conv = self.backbone.conv1\n",
    "        self.backbone.conv1 = nn.Conv2d(\n",
    "            20,\n",
    "            64,\n",
    "            kernel_size=original_first_conv.kernel_size,\n",
    "            stride=original_first_conv.stride,\n",
    "            padding=original_first_conv.padding,\n",
    "            bias=original_first_conv.bias is not None,\n",
    "        )\n",
    "\n",
    "        # Копируем веса из предобученной модели (усредняем по каналам)\n",
    "        if pretrained:\n",
    "            with torch.no_grad():\n",
    "                original_weights = original_first_conv.weight.data\n",
    "                # Усредняем веса по RGB каналам и повторяем для 20 каналов\n",
    "                mean_weights = original_weights.mean(dim=1, keepdim=True)\n",
    "                new_weights = mean_weights.repeat(1, 20, 1, 1) / 3.0\n",
    "                self.backbone.conv1.weight.data = new_weights\n",
    "\n",
    "        # 2. Убираем последние слои (avgpool и classifier)\n",
    "        backbone_layers = list(self.backbone.children())[:-2]\n",
    "        self.backbone = nn.Sequential(*backbone_layers)\n",
    "\n",
    "        # 3. Attention механизмы на разных уровнях ResNet\n",
    "        class SpatialAttention(nn.Module):\n",
    "            def __init__(self, channels, reduction=16):\n",
    "                super().__init__()\n",
    "                # Channel attention\n",
    "                self.channel_attention = nn.Sequential(\n",
    "                    nn.AdaptiveAvgPool2d(1),\n",
    "                    nn.Conv2d(channels, channels // reduction, 1, bias=False),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Conv2d(channels // reduction, channels, 1, bias=False),\n",
    "                    nn.Sigmoid(),\n",
    "                )\n",
    "                # Spatial attention\n",
    "                self.spatial_attention = nn.Sequential(\n",
    "                    nn.Conv2d(2, 1, kernel_size=7, padding=3, bias=False), nn.Sigmoid()\n",
    "                )\n",
    "\n",
    "            def forward(self, x):\n",
    "                # Channel attention\n",
    "                ca = self.channel_attention(x)\n",
    "                x_ca = x * ca\n",
    "\n",
    "                # Spatial attention\n",
    "                avg_out = torch.mean(x_ca, dim=1, keepdim=True)\n",
    "                max_out, _ = torch.max(x_ca, dim=1, keepdim=True)\n",
    "                sa_input = torch.cat([avg_out, max_out], dim=1)\n",
    "                sa = self.spatial_attention(sa_input)\n",
    "                x_sa = x_ca * sa\n",
    "\n",
    "                return x_sa, sa\n",
    "\n",
    "        # Добавляем attention механизмы к разным слоям ResNet\n",
    "        self.attention1 = SpatialAttention(256)  # После layer1\n",
    "        self.attention2 = SpatialAttention(512)  # После layer2\n",
    "        self.attention3 = SpatialAttention(1024)  # После layer3\n",
    "        self.attention4 = SpatialAttention(2048)  # После layer4\n",
    "\n",
    "        # Adaptive pooling для приведения к размеру 8x8\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((8, 8))\n",
    "\n",
    "        # BatchNorm и Dropout для стабилизации\n",
    "        self.from_bn1 = nn.BatchNorm1d(512)\n",
    "        self.from_dropout = nn.Dropout(0.3)\n",
    "\n",
    "        self.to_bn1 = nn.BatchNorm2d(2048 + 64)  # ResNet features + one-hot\n",
    "        self.to_bn2 = nn.BatchNorm1d(512)\n",
    "        self.to_dropout = nn.Dropout(0.3)\n",
    "\n",
    "        # Голова для исходной клетки\n",
    "        self.from_conv_reduce = nn.Conv2d(2048, 256, 1)  # Уменьшаем размерность\n",
    "        self.from_bn_conv = nn.BatchNorm2d(256)\n",
    "        self.from_fc1 = nn.Linear(256 * 8 * 8, 512)\n",
    "        self.from_output = nn.Linear(512, 64)\n",
    "\n",
    "        # Голова для целевой клетки\n",
    "        self.to_conv1 = nn.Conv2d(2048 + 64, 512, 3, padding=1)\n",
    "        self.to_conv2 = nn.Conv2d(512, 256, 3, padding=1)\n",
    "        self.to_fc1 = nn.Linear(256 * 8 * 8, 512)\n",
    "        self.to_output = nn.Linear(512, 69)  # 64 клетки + 5 превращения\n",
    "\n",
    "        # Дополнительные слои для feature fusion\n",
    "        self.feature_fusion_conv = nn.Conv2d(2048, 512, 1)\n",
    "        self.feature_fusion_bn = nn.BatchNorm2d(512)\n",
    "\n",
    "        # Инициализация весов\n",
    "        self._initialize_weights()\n",
    "\n",
    "        # Перенос на устройство\n",
    "        self.to(device)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Инициализация весов для новых слоев\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, board_tensor, from_square=None):\n",
    "        batch_size = board_tensor.size(0)\n",
    "        # Проход через ResNet backbone с attention механизмами\n",
    "        x = self.backbone.conv1(board_tensor)\n",
    "        x = self.backbone.bn1(x)\n",
    "        x = self.backbone.relu(x)\n",
    "        x = self.backbone.maxpool(x)\n",
    "\n",
    "        # Layer 1 с attention\n",
    "        x = self.backbone.layer1(x)\n",
    "        x, att1 = self.attention1(x)\n",
    "\n",
    "        # Layer 2 с attention\n",
    "        x = self.backbone.layer2(x)\n",
    "        x, att2 = self.attention2(x)\n",
    "\n",
    "        # Layer 3 с attention\n",
    "        x = self.backbone.layer3(x)\n",
    "        x, att3 = self.attention3(x)\n",
    "\n",
    "        # Layer 4 с attention\n",
    "        x = self.backbone.layer4(x)\n",
    "        shared_features, att4 = self.attention4(x)\n",
    "\n",
    "        # Приводим к размеру 8x8\n",
    "        shared_features = self.adaptive_pool(shared_features)\n",
    "\n",
    "        # Голова для исходной клетки\n",
    "        from_features = F.relu(\n",
    "            self.from_bn_conv(self.from_conv_reduce(shared_features))\n",
    "        )\n",
    "        from_flat = from_features.reshape(from_features.size(0), -1)\n",
    "        from_hidden = F.relu(self.from_fc1(from_flat))\n",
    "        from_hidden = self.from_bn1(from_hidden)\n",
    "        from_hidden = self.from_dropout(from_hidden)\n",
    "        from_logits = self.from_output(from_hidden)\n",
    "\n",
    "        from_probs = F.log_softmax(from_logits, dim=1)\n",
    "\n",
    "        # Если только предсказание from_square\n",
    "        if from_square is None:\n",
    "            return from_probs, None, [att1, att2, att3, att4]\n",
    "\n",
    "        # Голова для целевой клетки\n",
    "        # Создаем one-hot кодирование для from_square\n",
    "        from_onehot = torch.zeros(batch_size, 64, 8, 8, device=self.device)\n",
    "        from_onehot[torch.arange(batch_size), from_square, :, :] = 1\n",
    "\n",
    "        # Конкатенируем ResNet features с one-hot кодированием\n",
    "        to_input = torch.cat([shared_features, from_onehot], dim=1)\n",
    "\n",
    "        # Обработка через сверточные слои\n",
    "        to_features = F.relu(self.to_conv1(to_input))\n",
    "        to_features = self.to_bn1(to_features)\n",
    "        to_features = F.relu(self.to_conv2(to_features))\n",
    "\n",
    "        # Полносвязные слои\n",
    "        to_flat = to_features.reshape(to_features.size(0), -1)\n",
    "        to_hidden = F.relu(self.to_fc1(to_flat))\n",
    "        to_hidden = self.to_bn2(to_hidden)\n",
    "        to_hidden = self.to_dropout(to_hidden)\n",
    "        to_logits = self.to_output(to_hidden)\n",
    "\n",
    "        to_probs = F.log_softmax(to_logits, dim=1)\n",
    "\n",
    "        return from_probs, to_probs, [att1, att2, att3, att4]\n",
    "\n",
    "    def get_attention_maps(self, board_tensor, layer_idx=3):\n",
    "        \"\"\"Возвращает карты внимания для визуализации\"\"\"\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            _, _, attention_weights = self.forward(board_tensor)\n",
    "            return attention_weights[layer_idx].squeeze().cpu().numpy()\n",
    "\n",
    "    def predict_full_move(self, board_tensor):\n",
    "        \"\"\"Предсказывает полный ход (from_square и to_square)\"\"\"\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            # Предсказываем from_square\n",
    "            from_probs, _, attention_weights = self.forward(board_tensor)\n",
    "            from_square_pred = torch.argmax(from_probs, dim=1)\n",
    "\n",
    "            # Предсказываем to_square на основе from_square_pred\n",
    "            _, to_probs, _ = self.forward(board_tensor, from_square_pred)\n",
    "            to_square_pred = torch.argmax(to_probs, dim=1)\n",
    "\n",
    "            return from_square_pred, to_square_pred, attention_weights\n",
    "\n",
    "    def get_feature_maps(self, board_tensor):\n",
    "        \"\"\"Возвращает feature maps с разных уровней ResNet\"\"\"\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            batch_size = board_tensor.size(0)\n",
    "\n",
    "            # Проход через ResNet с сохранением промежуточных features\n",
    "            x = self.backbone.conv1(board_tensor)\n",
    "            x = self.backbone.bn1(x)\n",
    "            x = self.backbone.relu(x)\n",
    "            x = self.backbone.maxpool(x)\n",
    "\n",
    "            layer1_out = self.backbone.layer1(x)\n",
    "            layer1_att, att1 = self.attention1(layer1_out)\n",
    "\n",
    "            layer2_out = self.backbone.layer2(layer1_att)\n",
    "            layer2_att, att2 = self.attention2(layer2_out)\n",
    "\n",
    "            layer3_out = self.backbone.layer3(layer2_att)\n",
    "            layer3_att, att3 = self.attention3(layer3_out)\n",
    "\n",
    "            layer4_out = self.backbone.layer4(layer3_att)\n",
    "            final_features, att4 = self.attention4(layer4_out)\n",
    "\n",
    "            final_features_pooled = self.adaptive_pool(final_features)\n",
    "\n",
    "            return {\n",
    "                \"layer1\": layer1_out,\n",
    "                \"layer2\": layer2_out,\n",
    "                \"layer3\": layer3_out,\n",
    "                \"layer4\": layer4_out,\n",
    "                \"final_features\": final_features_pooled,\n",
    "                \"attention_maps\": [att1, att2, att3, att4],\n",
    "            }\n",
    "\n",
    "    def freeze_backbone(self):\n",
    "        \"\"\"Замораживает веса ResNet backbone для transfer learning\"\"\"\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Размораживаем attention механизмы\n",
    "        for param in self.attention1.parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in self.attention2.parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in self.attention3.parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in self.attention4.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def unfreeze_backbone(self):\n",
    "        \"\"\"Размораживает все веса\"\"\"\n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9842fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessTrainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        test_loader,\n",
    "        device=\"cpu\",\n",
    "        lr=0.001,  # Уменьшил learning rate для ResNet\n",
    "        weight_decay=0.01,\n",
    "    ):\n",
    "        self.model = model.to(device)\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.device = device\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "\n",
    "        # Функции потерь для dual-head архитектуры\n",
    "        self.from_criterion = nn.NLLLoss()  # Т.к. используем log_softmax\n",
    "        self.to_criterion = nn.NLLLoss()\n",
    "\n",
    "        # Оптимизатор\n",
    "        self.optimizer = optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=self.lr,\n",
    "            weight_decay=self.weight_decay,\n",
    "        )\n",
    "\n",
    "        # Планировщик learning rate\n",
    "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
    "        )\n",
    "\n",
    "        # История обучения\n",
    "        self.history = {\n",
    "            \"train_loss\": [],\n",
    "            \"val_loss\": [],\n",
    "            \"train_from_acc\": [],\n",
    "            \"val_from_acc\": [],\n",
    "            \"train_to_acc\": [],\n",
    "            \"val_to_acc\": [],\n",
    "            \"learning_rate\": [],\n",
    "            \"attention_maps\": []  # Для сохранения примеров attention maps\n",
    "        }\n",
    "\n",
    "    def train_epoch(self):\n",
    "        \"\"\"Одна эпоха обучения для dual-head модели\"\"\"\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        total_from_correct = 0\n",
    "        total_to_correct = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        train_bar = tqdm(self.train_loader, desc=\"Training\")\n",
    "\n",
    "        for batch_idx, (boards, from_targets, to_targets) in enumerate(train_bar):\n",
    "            # Перемещаем данные на device\n",
    "            boards = boards.to(self.device)\n",
    "            from_targets = from_targets.to(self.device)\n",
    "            to_targets = to_targets.to(self.device)\n",
    "\n",
    "            # Обнуляем градиенты\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            # Прямой проход через dual-head модель\n",
    "            from_probs, to_probs, attention_weights = self.model(boards, from_targets)\n",
    "\n",
    "            # Вычисляем потери для обеих голов\n",
    "            from_loss = self.from_criterion(from_probs, from_targets)\n",
    "            to_loss = self.to_criterion(to_probs, to_targets)\n",
    "            \n",
    "            # Комбинируем потери\n",
    "            loss = from_loss + to_loss\n",
    "\n",
    "            # Обратный проход\n",
    "            loss.backward()\n",
    "\n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "\n",
    "            # Шаг оптимизатора\n",
    "            self.optimizer.step()\n",
    "\n",
    "            # Статистика\n",
    "            total_loss += loss.item()\n",
    "            batch_size = boards.size(0)\n",
    "            total_samples += batch_size\n",
    "\n",
    "            # Точность для from-square\n",
    "            from_preds = torch.argmax(from_probs, dim=1)\n",
    "            from_correct = (from_preds == from_targets).sum().item()\n",
    "            total_from_correct += from_correct\n",
    "\n",
    "            # Точность для to-square\n",
    "            to_preds = torch.argmax(to_probs, dim=1)\n",
    "            to_correct = (to_preds == to_targets).sum().item()\n",
    "            total_to_correct += to_correct\n",
    "\n",
    "            # Обновляем progress bar\n",
    "            train_bar.set_postfix(\n",
    "                {\n",
    "                    \"Loss\": f\"{loss.item():.4f}\",\n",
    "                    \"From Acc\": f\"{from_correct / batch_size:.3f}\",\n",
    "                    \"To Acc\": f\"{to_correct / batch_size:.3f}\",\n",
    "                }\n",
    "            )\n",
    "\n",
    "        # Вычисляем средние метрики за эпоху\n",
    "        avg_loss = total_loss / len(self.train_loader)\n",
    "        from_acc = total_from_correct / total_samples\n",
    "        to_acc = total_to_correct / total_samples\n",
    "\n",
    "        return avg_loss, from_acc, to_acc\n",
    "\n",
    "    def validate(self):\n",
    "        \"\"\"Валидация dual-head модели\"\"\"\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        total_from_correct = 0\n",
    "        total_to_correct = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        # Сохраняем пример attention maps для визуализации\n",
    "        sample_attention_maps = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (boards, from_targets, to_targets) in enumerate(tqdm(\n",
    "                self.val_loader, desc=\"Validation\"\n",
    "            )):\n",
    "                boards = boards.to(self.device)\n",
    "                from_targets = from_targets.to(self.device)\n",
    "                to_targets = to_targets.to(self.device)\n",
    "\n",
    "                # Прямой проход\n",
    "                from_probs, to_probs, attention_weights = self.model(boards, from_targets)\n",
    "\n",
    "                # Потери\n",
    "                from_loss = self.from_criterion(from_probs, from_targets)\n",
    "                to_loss = self.to_criterion(to_probs, to_targets)\n",
    "                loss = from_loss + to_loss\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                batch_size = boards.size(0)\n",
    "                total_samples += batch_size\n",
    "\n",
    "                # Точность\n",
    "                from_preds = torch.argmax(from_probs, dim=1)\n",
    "                from_correct = (from_preds == from_targets).sum().item()\n",
    "                total_from_correct += from_correct\n",
    "\n",
    "                to_preds = torch.argmax(to_probs, dim=1)\n",
    "                to_correct = (to_preds == to_targets).sum().item()\n",
    "                total_to_correct += to_correct\n",
    "\n",
    "                # Сохраняем attention maps из первого батча\n",
    "                if batch_idx == 0 and len(sample_attention_maps) == 0:\n",
    "                    sample_attention_maps = attention_weights\n",
    "\n",
    "        avg_loss = total_loss / len(self.val_loader)\n",
    "        from_acc = total_from_correct / total_samples\n",
    "        to_acc = total_to_correct / total_samples\n",
    "\n",
    "        return avg_loss, from_acc, to_acc, sample_attention_maps\n",
    "\n",
    "    def train(self, num_epochs=50, early_stopping_patience=10):\n",
    "        \"\"\"Полный цикл обучения для dual-head модели\"\"\"\n",
    "        best_val_loss = float(\"inf\")\n",
    "        patience_counter = 0\n",
    "\n",
    "        print(\"Начало обучения ResidualCNNWithAttention модели...\")\n",
    "        print(f\"Используется устройство: {self.device}\")\n",
    "        print(f\"Размер тренировочного набора: {len(self.train_loader.dataset)}\")\n",
    "        print(f\"Размер валидационного набора: {len(self.val_loader.dataset)}\")\n",
    "        print(f\"Architecture: ResNet-50 backbone + Attention + Dual Heads\")\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f\"\\nЭпоха {epoch + 1}/{num_epochs}\")\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "            # Обучение\n",
    "            train_loss, train_from_acc, train_to_acc = self.train_epoch()\n",
    "\n",
    "            # Валидация\n",
    "            val_loss, val_from_acc, val_to_acc, attention_maps = self.validate()\n",
    "\n",
    "            # Обновление learning rate\n",
    "            self.scheduler.step(val_loss)\n",
    "            current_lr = self.optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "            # Сохраняем историю\n",
    "            self.history[\"train_loss\"].append(train_loss)\n",
    "            self.history[\"val_loss\"].append(val_loss)\n",
    "            self.history[\"train_from_acc\"].append(train_from_acc)\n",
    "            self.history[\"val_from_acc\"].append(val_from_acc)\n",
    "            self.history[\"train_to_acc\"].append(train_to_acc)\n",
    "            self.history[\"val_to_acc\"].append(val_to_acc)\n",
    "            self.history[\"learning_rate\"].append(current_lr)\n",
    "            self.history[\"attention_maps\"].append(attention_maps)\n",
    "\n",
    "            # Выводим результаты\n",
    "            print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "            print(f\"Train From Acc: {train_from_acc:.4f} | Val From Acc: {val_from_acc:.4f}\")\n",
    "            print(f\"Train To Acc: {train_to_acc:.4f} | Val To Acc: {val_to_acc:.4f}\")\n",
    "            print(f\"Learning Rate: {current_lr:.6f}\")\n",
    "\n",
    "            # Сохранение лучшей модели\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                patience_counter = 0\n",
    "                self.save_model(\"best_chess_resnet_attention_model.pth\")\n",
    "                print(\"Сохранена лучшая модель!\")\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                print(f\"Early stopping: {patience_counter}/{early_stopping_patience}\")\n",
    "\n",
    "            # Early stopping\n",
    "            if patience_counter >= early_stopping_patience:\n",
    "                print(\"Ранняя остановка!\")\n",
    "                break\n",
    "\n",
    "        print(\"\\nОбучение завершено!\")\n",
    "        self.plot_training_history()\n",
    "\n",
    "    def evaluate(self):\n",
    "        \"\"\"Финальная оценка на тестовом наборе\"\"\"\n",
    "        print(\"\\nОценка на тестовом наборе...\")\n",
    "        self.model.eval()\n",
    "\n",
    "        total_from_correct = 0\n",
    "        total_to_correct = 0\n",
    "        total_full_correct = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for boards, from_targets, to_targets in tqdm(\n",
    "                self.test_loader, desc=\"Testing\"\n",
    "            ):\n",
    "                boards = boards.to(self.device)\n",
    "                from_targets = from_targets.to(self.device)\n",
    "                to_targets = to_targets.to(self.device)\n",
    "\n",
    "                # Предсказание from-square\n",
    "                from_probs, _, _ = self.model(boards)\n",
    "                from_preds = torch.argmax(from_probs, dim=1)\n",
    "\n",
    "                # Предсказание to-square (используя правильные from-square для честной оценки)\n",
    "                _, to_probs, _ = self.model(boards, from_targets)\n",
    "                to_preds = torch.argmax(to_probs, dim=1)\n",
    "\n",
    "                # Подсчет правильных предсказаний\n",
    "                batch_size = boards.size(0)\n",
    "                total_samples += batch_size\n",
    "                \n",
    "                from_correct = (from_preds == from_targets).sum().item()\n",
    "                to_correct = (to_preds == to_targets).sum().item()\n",
    "                full_correct = ((from_preds == from_targets) & (to_preds == to_targets)).sum().item()\n",
    "\n",
    "                total_from_correct += from_correct\n",
    "                total_to_correct += to_correct\n",
    "                total_full_correct += full_correct\n",
    "\n",
    "        from_acc = total_from_correct / total_samples\n",
    "        to_acc = total_to_correct / total_samples\n",
    "        full_acc = total_full_correct / total_samples\n",
    "\n",
    "        print(f\"\\nРезультаты на тестовом наборе:\")\n",
    "        print(f\"From-square Accuracy: {from_acc:.4f}\")\n",
    "        print(f\"To-square Accuracy: {to_acc:.4f}\")\n",
    "        print(f\"Full Move Accuracy: {full_acc:.4f}\")\n",
    "\n",
    "        return from_acc, to_acc, full_acc\n",
    "\n",
    "    def predict_single_move(self, board_tensor):\n",
    "        \"\"\"Предсказание хода для одного тензора доски\"\"\"\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            # Предсказываем from_square\n",
    "            from_probs, _, _ = self.model(board_tensor.unsqueeze(0))\n",
    "            from_square = torch.argmax(from_probs, dim=1).item()\n",
    "            \n",
    "            # Предсказываем to_square на основе предсказанного from_square\n",
    "            _, to_probs, attention_weights = self.model(\n",
    "                board_tensor.unsqueeze(0), \n",
    "                torch.tensor([from_square], device=self.device)\n",
    "            )\n",
    "            to_square = torch.argmax(to_probs, dim=1).item()\n",
    "            \n",
    "            return from_square, to_square, attention_weights\n",
    "\n",
    "    def analyze_attention(self, board_tensor):\n",
    "        \"\"\"Анализ attention maps для заданной позиции\"\"\"\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            from_probs, _, attention_weights = self.model(board_tensor.unsqueeze(0))\n",
    "            from_square = torch.argmax(from_probs, dim=1).item()\n",
    "            \n",
    "            # Получаем feature maps для анализа\n",
    "            feature_maps = self.model.get_feature_maps(board_tensor.unsqueeze(0))\n",
    "            \n",
    "            return {\n",
    "                'from_square_pred': from_square,\n",
    "                'attention_weights': attention_weights,\n",
    "                'feature_maps': feature_maps\n",
    "            }\n",
    "\n",
    "    def save_model(self, path):\n",
    "        \"\"\"Сохранение модели\"\"\"\n",
    "        torch.save(\n",
    "            {\n",
    "                \"model_state_dict\": self.model.state_dict(),\n",
    "                \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "                \"scheduler_state_dict\": self.scheduler.state_dict(),\n",
    "                \"history\": self.history,\n",
    "                \"epoch\": len(self.history[\"train_loss\"]),\n",
    "            },\n",
    "            path,\n",
    "        )\n",
    "\n",
    "    def load_model(self, path):\n",
    "        \"\"\"Загрузка модели\"\"\"\n",
    "        checkpoint = torch.load(path, map_location=self.device)\n",
    "        self.model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        self.optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "        self.scheduler.load_state_dict(checkpoint[\"scheduler_state_dict\"])\n",
    "        self.history = checkpoint[\"history\"]\n",
    "\n",
    "    def plot_training_history(self):\n",
    "        \"\"\"Визуализация истории обучения\"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "        # Потери\n",
    "        ax1.plot(self.history[\"train_loss\"], label=\"Train Loss\", linewidth=2)\n",
    "        ax1.plot(self.history[\"val_loss\"], label=\"Val Loss\", linewidth=2)\n",
    "        ax1.set_title(\"Потери\", fontsize=14)\n",
    "        ax1.set_xlabel(\"Эпоха\")\n",
    "        ax1.set_ylabel(\"Loss\")\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "\n",
    "        # From-square точность\n",
    "        ax2.plot(self.history[\"train_from_acc\"], label=\"Train From Acc\", linewidth=2)\n",
    "        ax2.plot(self.history[\"val_from_acc\"], label=\"Val From Acc\", linewidth=2)\n",
    "        ax2.set_title(\"From-square Точность\", fontsize=14)\n",
    "        ax2.set_xlabel(\"Эпоха\")\n",
    "        ax2.set_ylabel(\"Accuracy\")\n",
    "        ax2.legend()\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "\n",
    "        # To-square точность\n",
    "        ax3.plot(self.history[\"train_to_acc\"], label=\"Train To Acc\", linewidth=2)\n",
    "        ax3.plot(self.history[\"val_to_acc\"], label=\"Val To Acc\", linewidth=2)\n",
    "        ax3.set_title(\"To-square Точность\", fontsize=14)\n",
    "        ax3.set_xlabel(\"Эпоха\")\n",
    "        ax3.set_ylabel(\"Accuracy\")\n",
    "        ax3.legend()\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "\n",
    "        # Learning rate\n",
    "        ax4.plot(self.history[\"learning_rate\"], linewidth=2, color='purple')\n",
    "        ax4.set_title(\"Learning Rate\", fontsize=14)\n",
    "        ax4.set_xlabel(\"Эпоха\")\n",
    "        ax4.set_ylabel(\"LR\")\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "        ax4.set_yscale('log')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"training_history_resnet_attention.png\", dpi=300, bbox_inches=\"tight\")\n",
    "        plt.show()\n",
    "\n",
    "    def plot_attention_maps(self, board_tensor, epoch=-1):\n",
    "        \"\"\"Визуализация attention maps для примера доски\"\"\"\n",
    "        if len(self.history[\"attention_maps\"]) == 0:\n",
    "            print(\"No attention maps available\")\n",
    "            return\n",
    "        \n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        attention_maps = self.history[\"attention_maps\"][epoch]\n",
    "        if isinstance(attention_maps, list):\n",
    "            # Берем последний уровень attention (самый высокоуровневый)\n",
    "            attention_map = attention_maps[-1][0].cpu().numpy()  # [1, 8, 8]\n",
    "        else:\n",
    "            attention_map = attention_maps[0].cpu().numpy()\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        \n",
    "        # Исходная доска\n",
    "        board_vis = board_tensor[:12].sum(dim=0).cpu().numpy()  # Сумма по фигурам\n",
    "        ax1.imshow(board_vis, cmap='RdYlBu_r')\n",
    "        ax1.set_title(\"Шахматная доска\")\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Attention map\n",
    "        im = ax2.imshow(attention_map.squeeze(), cmap='hot', interpolation='nearest')\n",
    "        ax2.set_title(\"Attention Map\")\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        plt.colorbar(im, ax=ax2)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"attention_visualization.png\", dpi=300, bbox_inches=\"tight\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47564f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Используется устройство: {device}\")\n",
    "\n",
    "    # Загрузка данных\n",
    "    print(\"Загрузка данных...\")\n",
    "    splitter = ChessDataSplitter(\n",
    "        test_ratio=0.01,\n",
    "        val_ratio=0.2 * (1 - 0.01),\n",
    "        train_ratio=0.8 * (1 - 0.01),\n",
    "        csv_file=\"fens_training_set.csv\",\n",
    "        random_state=seed\n",
    "    )\n",
    "    train_dataset, val_dataset, test_dataset = splitter.split_data()\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "    # Модель\n",
    "    print(\"Инициализация модели...\")\n",
    "    model = ResidualCNNWithAttention()\n",
    "\n",
    "    # Тренер\n",
    "    trainer = ChessTrainer(model, train_loader, val_loader, test_loader, device)\n",
    "\n",
    "    # Обучение\n",
    "    trainer.train(num_epochs=20, early_stopping_patience=10)\n",
    "\n",
    "    # Валидация\n",
    "    trainer.validate()\n",
    "\n",
    "    # # Сохранение финальной модели\n",
    "    # trainer.save_model(\"final_chess_model.pth\")\n",
    "    # print(\"Модель сохранена!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79bfaaea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используется устройство: cpu\n",
      "Загрузка данных...\n",
      "0.792 0.198 0.01\n",
      "Загружено 268549 валидных позиций\n",
      "Разбиение завершено:\n",
      "Train: 212690 samples (79.2%)\n",
      "Val: 53173 samples (19.8%)\n",
      "Test: 2686 samples (1.0%)\n",
      "Инициализация модели...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivan/Desktop/универ/.venv/lib/python3.13/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/ivan/Desktop/универ/.venv/lib/python3.13/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /Users/ivan/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 17.1M/97.8M [06:20<29:51, 47.2kB/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Модель\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mИнициализация модели...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m model = \u001b[43mResidualCNNWithAttention\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Тренер\u001b[39;00m\n\u001b[32m     24\u001b[39m trainer = ChessTrainer(model, train_loader, val_loader, test_loader, device)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mResidualCNNWithAttention.__init__\u001b[39m\u001b[34m(self, device, pretrained)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mself\u001b[39m.device = device\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# ResNet-50 backbone\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28mself\u001b[39m.backbone = \u001b[43mresnet50\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Модифицируем ResNet для работы с нашими данными\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# 1. Заменяем первый слой для 20 каналов (входные плоскости шахматной доски)\u001b[39;00m\n\u001b[32m     11\u001b[39m original_first_conv = \u001b[38;5;28mself\u001b[39m.backbone.conv1\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/универ/.venv/lib/python3.13/site-packages/torchvision/models/_utils.py:142\u001b[39m, in \u001b[36mkwonly_to_pos_or_kw.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    135\u001b[39m     warnings.warn(\n\u001b[32m    136\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUsing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msequence_to_str(\u001b[38;5;28mtuple\u001b[39m(keyword_only_kwargs.keys()),\u001b[38;5;250m \u001b[39mseparate_last=\u001b[33m'\u001b[39m\u001b[33mand \u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m as positional \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    137\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    138\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33minstead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    139\u001b[39m     )\n\u001b[32m    140\u001b[39m     kwargs.update(keyword_only_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/универ/.venv/lib/python3.13/site-packages/torchvision/models/_utils.py:228\u001b[39m, in \u001b[36mhandle_legacy_interface.<locals>.outer_wrapper.<locals>.inner_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    225\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[pretrained_param]\n\u001b[32m    226\u001b[39m     kwargs[weights_param] = default_weights_arg\n\u001b[32m--> \u001b[39m\u001b[32m228\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuilder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/универ/.venv/lib/python3.13/site-packages/torchvision/models/resnet.py:763\u001b[39m, in \u001b[36mresnet50\u001b[39m\u001b[34m(weights, progress, **kwargs)\u001b[39m\n\u001b[32m    737\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"ResNet-50 from `Deep Residual Learning for Image Recognition <https://arxiv.org/abs/1512.03385>`__.\u001b[39;00m\n\u001b[32m    738\u001b[39m \n\u001b[32m    739\u001b[39m \u001b[33;03m.. note::\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    759\u001b[39m \u001b[33;03m    :members:\u001b[39;00m\n\u001b[32m    760\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    761\u001b[39m weights = ResNet50_Weights.verify(weights)\n\u001b[32m--> \u001b[39m\u001b[32m763\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_resnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBottleneck\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/универ/.venv/lib/python3.13/site-packages/torchvision/models/resnet.py:301\u001b[39m, in \u001b[36m_resnet\u001b[39m\u001b[34m(block, layers, weights, progress, **kwargs)\u001b[39m\n\u001b[32m    298\u001b[39m model = ResNet(block, layers, **kwargs)\n\u001b[32m    300\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m301\u001b[39m     model.load_state_dict(\u001b[43mweights\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[32m    303\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/универ/.venv/lib/python3.13/site-packages/torchvision/models/_api.py:91\u001b[39m, in \u001b[36mWeightsEnum.get_state_dict\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_state_dict\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> Mapping[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_state_dict_from_url\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/универ/.venv/lib/python3.13/site-packages/torch/hub.py:871\u001b[39m, in \u001b[36mload_state_dict_from_url\u001b[39m\u001b[34m(url, model_dir, map_location, progress, check_hash, file_name, weights_only)\u001b[39m\n\u001b[32m    869\u001b[39m         r = HASH_REGEX.search(filename)  \u001b[38;5;66;03m# r is Optional[Match[str]]\u001b[39;00m\n\u001b[32m    870\u001b[39m         hash_prefix = r.group(\u001b[32m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m r \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m871\u001b[39m     \u001b[43mdownload_url_to_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcached_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhash_prefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _is_legacy_zip_format(cached_file):\n\u001b[32m    874\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _legacy_zip_load(cached_file, model_dir, map_location, weights_only)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/универ/.venv/lib/python3.13/site-packages/torch/hub.py:748\u001b[39m, in \u001b[36mdownload_url_to_file\u001b[39m\u001b[34m(url, dst, hash_prefix, progress)\u001b[39m\n\u001b[32m    740\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(\n\u001b[32m    741\u001b[39m     total=file_size,\n\u001b[32m    742\u001b[39m     disable=\u001b[38;5;129;01mnot\u001b[39;00m progress,\n\u001b[32m   (...)\u001b[39m\u001b[32m    745\u001b[39m     unit_divisor=\u001b[32m1024\u001b[39m,\n\u001b[32m    746\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[32m    747\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m748\u001b[39m         buffer = \u001b[43mu\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mREAD_DATA_CHUNK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    749\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) == \u001b[32m0\u001b[39m:\n\u001b[32m    750\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:479\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt > \u001b[38;5;28mself\u001b[39m.length:\n\u001b[32m    477\u001b[39m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[32m    478\u001b[39m     amt = \u001b[38;5;28mself\u001b[39m.length\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m s = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[32m    481\u001b[39m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[32m    482\u001b[39m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[32m    483\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_conn()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/socket.py:719\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot read from timed out object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    721\u001b[39m     \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1304\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1300\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1301\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1302\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1303\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1138\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1140\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a62c66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
