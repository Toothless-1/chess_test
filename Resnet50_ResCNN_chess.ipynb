{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "459ef6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision.models import resnet50\n",
    "from typing import List, Tuple\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "seed = 123456\n",
    "np.random.seed(seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215217a3",
   "metadata": {},
   "source": [
    "# Разработка модели\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "731c677a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualHeadChessDataset(Dataset):\n",
    "    def __init__(self, csv_file: str):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "\n",
    "        self._validate_data()\n",
    "        self.piece_to_idx = {\n",
    "            \"P\": 0,\n",
    "            \"N\": 1,\n",
    "            \"B\": 2,\n",
    "            \"R\": 3,\n",
    "            \"Q\": 4,\n",
    "            \"K\": 5,\n",
    "            \"p\": 6,\n",
    "            \"n\": 7,\n",
    "            \"b\": 8,\n",
    "            \"r\": 9,\n",
    "            \"q\": 10,\n",
    "            \"k\": 11,\n",
    "        }\n",
    "\n",
    "    def _validate_data(self):\n",
    "        valid_indices = []\n",
    "        for idx, row in self.df.iterrows():\n",
    "            try:\n",
    "                board = chess.Board(row[\"fen\"])\n",
    "                move = chess.Move.from_uci(row[\"move\"])\n",
    "                if move in board.legal_moves:\n",
    "                    valid_indices.append(idx)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        self.df = self.df.loc[valid_indices].reset_index(drop=True)\n",
    "        print(f\"Загружено {len(self.df)} валидных позиций\")\n",
    "\n",
    "    def _board_to_tensor(self, fen: str) -> torch.Tensor:\n",
    "        board = chess.Board(fen)\n",
    "        tensor = torch.zeros(20, 8, 8, dtype=torch.float32)\n",
    "\n",
    "        # Фигуры (плоскости 0-11)\n",
    "        for square in chess.SQUARES:\n",
    "            piece = board.piece_at(square)\n",
    "            if piece:\n",
    "                row, col = square // 8, square % 8\n",
    "                piece_idx = self.piece_to_idx[piece.symbol()]\n",
    "                tensor[piece_idx, row, col] = 1.0\n",
    "\n",
    "        # Чей ход (плоскость 12)\n",
    "        tensor[12] = 1.0 if board.turn else 0.0\n",
    "\n",
    "        # Рокировки (плоскости 13-16)\n",
    "        castling_rights = [\n",
    "            board.has_kingside_castling_rights(chess.WHITE),\n",
    "            board.has_queenside_castling_rights(chess.WHITE),\n",
    "            board.has_kingside_castling_rights(chess.BLACK),\n",
    "            board.has_queenside_castling_rights(chess.BLACK),\n",
    "        ]\n",
    "        for i, has_right in enumerate(castling_rights):\n",
    "            if has_right:\n",
    "                tensor[13 + i] = 1.0\n",
    "\n",
    "        # Взятие на проходе (плоскость 17)\n",
    "        if board.ep_square is not None:\n",
    "            row, col = board.ep_square // 8, board.ep_square % 8\n",
    "            tensor[17, row, col] = 1.0\n",
    "\n",
    "        # Счетчик полуходов (плоскость 18)\n",
    "        tensor[18] = board.halfmove_clock / 50.0\n",
    "\n",
    "        # Номер хода (плоскость 19)\n",
    "        tensor[19] = board.fullmove_number / 500.0\n",
    "\n",
    "        return tensor\n",
    "\n",
    "    def _move_to_dual_labels(self, move_uci: str, fen: str) -> tuple:\n",
    "        board = chess.Board(fen)\n",
    "        move = chess.Move.from_uci(move_uci)\n",
    "\n",
    "        from_square = move.from_square\n",
    "\n",
    "        # Для to_square учитываем превращения\n",
    "        # ДИАПАЗОН ДОЛЖЕН БЫТЬ 0-68 (69 классов)\n",
    "        # print(move.promotion)\n",
    "        if move.promotion:\n",
    "            # Кодируем превращения: 64-68\n",
    "            to_square = 64 + (move.promotion - 1)  # 64, 65, 66, 67, 68\n",
    "        else:\n",
    "            to_square = move.to_square  # 0-63\n",
    "\n",
    "        # Проверяем, что to_square в правильном диапазоне\n",
    "        if to_square >= 69:\n",
    "            raise ValueError(f\"Некорректный to_square: {to_square} для хода {move_uci}\")\n",
    "\n",
    "        return from_square, to_square\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        fen = row[\"fen\"]\n",
    "        move = row[\"move\"]\n",
    "\n",
    "        board_tensor = self._board_to_tensor(fen)\n",
    "        from_label, to_label = self._move_to_dual_labels(move, fen)\n",
    "\n",
    "        return board_tensor, from_label, to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d81e9b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessDataSplitter:\n",
    "    def __init__(\n",
    "        self,\n",
    "        csv_file,\n",
    "        train_ratio=0.7,\n",
    "        val_ratio=0.15,\n",
    "        test_ratio=0.15,\n",
    "        random_state=42,\n",
    "    ):\n",
    "        print(train_ratio, val_ratio, test_ratio)\n",
    "        assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6, (\n",
    "            \"Сумма долей должна быть равна 1\"\n",
    "        )\n",
    "\n",
    "        self.csv_file = csv_file\n",
    "        self.train_ratio = train_ratio\n",
    "        self.val_ratio = val_ratio\n",
    "        self.test_ratio = test_ratio\n",
    "        self.random_state = random_state\n",
    "\n",
    "        # Загружаем полный dataset\n",
    "        self.full_dataset = DualHeadChessDataset(csv_file)\n",
    "\n",
    "    def split_data(self):\n",
    "        \"\"\"Разбивает данные на train/val/test\"\"\"\n",
    "        # Получаем индексы\n",
    "        n_total = len(self.full_dataset)\n",
    "        indices = list(range(n_total))\n",
    "\n",
    "        # Первое разбиение: отделяем test\n",
    "        train_val_idx, test_idx = train_test_split(\n",
    "            indices,\n",
    "            test_size=self.test_ratio,\n",
    "            random_state=self.random_state,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "        # Второе разбиение: разделяем train и val\n",
    "        train_idx, val_idx = train_test_split(\n",
    "            train_val_idx,\n",
    "            test_size=self.val_ratio / (self.train_ratio + self.val_ratio),\n",
    "            random_state=self.random_state,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "        # Создаем Subset datasets\n",
    "        train_dataset = Subset(self.full_dataset, train_idx)\n",
    "        val_dataset = Subset(self.full_dataset, val_idx)\n",
    "        test_dataset = Subset(self.full_dataset, test_idx)\n",
    "\n",
    "        print(f\"Разбиение завершено:\")\n",
    "        print(\n",
    "            f\"Train: {len(train_dataset)} samples ({len(train_dataset) / n_total * 100:.1f}%)\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Val: {len(val_dataset)} samples ({len(val_dataset) / n_total * 100:.1f}%)\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Test: {len(test_dataset)} samples ({len(test_dataset) / n_total * 100:.1f}%)\"\n",
    "        )\n",
    "\n",
    "        return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d1ed00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualCNNWithAttention(nn.Module):\n",
    "    def __init__(self, device=\"cpu\", pretrained=True):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "\n",
    "        # Используем более легкую версию ResNet\n",
    "        self.backbone = resnet50(pretrained=pretrained)\n",
    "        \n",
    "        # Модифицируем первый слой для 20 каналов\n",
    "        original_conv1 = self.backbone.conv1\n",
    "        self.backbone.conv1 = nn.Conv2d(\n",
    "            20, 64,\n",
    "            kernel_size=original_conv1.kernel_size,\n",
    "            stride=original_conv1.stride,\n",
    "            padding=original_conv1.padding,\n",
    "            bias=original_conv1.bias is not None\n",
    "        )\n",
    "        \n",
    "        # Копируем веса из предобученной модели\n",
    "        if pretrained:\n",
    "            with torch.no_grad():\n",
    "                original_weights = original_conv1.weight.data\n",
    "                mean_weights = original_weights.mean(dim=1, keepdim=True)\n",
    "                new_weights = mean_weights.repeat(1, 20, 1, 1) / 3.0\n",
    "                self.backbone.conv1.weight.data = new_weights\n",
    "        \n",
    "        # Замораживаем первые слои ResNet\n",
    "        self._freeze_early_layers()\n",
    "        \n",
    "        # Упрощаем attention механизмы\n",
    "        self.attention4 = SimplifiedAttention(2048)  # Только последний слой\n",
    "        \n",
    "        # Уменьшаем размерность фич\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((4, 4))  # Уменьшаем с 8x8 до 4x4\n",
    "        \n",
    "        # Упрощаем головы\n",
    "        self.from_fc1 = nn.Linear(2048 * 4 * 4, 256)  # Уменьшаем размерность\n",
    "        self.from_output = nn.Linear(256, 64)\n",
    "        \n",
    "        self.to_conv1 = nn.Conv2d(2048 + 64, 256, 3, padding=1)  # Меньше каналов\n",
    "        self.to_fc1 = nn.Linear(256 * 4 * 4, 128)\n",
    "        self.to_output = nn.Linear(128, 69)\n",
    "        \n",
    "        # Заменяем BatchNorm на более быстрые альтернативы\n",
    "        self.from_ln1 = nn.LayerNorm(256)\n",
    "        self.to_ln1 = nn.LayerNorm(128)\n",
    "\n",
    "    def _freeze_early_layers(self):\n",
    "        \"\"\"Замораживаем ранние слои ResNet\"\"\"\n",
    "        # Замораживаем conv1, bn1, layer1, layer2\n",
    "        for param in self.backbone.conv1.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.backbone.bn1.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.backbone.layer1.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.backbone.layer2.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, board_tensor, from_square=None):\n",
    "        batch_size = board_tensor.size(0)\n",
    "        \n",
    "        # Убедимся, что входной тензор на правильном устройстве\n",
    "        board_tensor = board_tensor.to(self.device)\n",
    "        \n",
    "        # Проход через ResNet backbone (только незамороженные слои)\n",
    "        x = self.backbone.conv1(board_tensor)\n",
    "        x = self.backbone.bn1(x)\n",
    "        x = self.backbone.relu(x)\n",
    "        x = self.backbone.maxpool(x)\n",
    "        \n",
    "        # Пропускаем замороженные слои (проход без вычисления градиентов)\n",
    "        with torch.no_grad():\n",
    "            x = self.backbone.layer1(x)\n",
    "            x = self.backbone.layer2(x)\n",
    "        \n",
    "        # Обучаемые слои\n",
    "        x = self.backbone.layer3(x)\n",
    "        x = self.backbone.layer4(x)\n",
    "        \n",
    "        # Attention на последнем слое\n",
    "        shared_features, att4 = self.attention4(x)\n",
    "        \n",
    "        # Приводим к размеру 4x4\n",
    "        shared_features = self.adaptive_pool(shared_features)\n",
    "\n",
    "        # Голова для исходной клетки\n",
    "        from_flat = shared_features.reshape(shared_features.size(0), -1)\n",
    "        from_hidden = F.relu(self.from_fc1(from_flat))\n",
    "        from_hidden = self.from_ln1(from_hidden)\n",
    "        from_logits = self.from_output(from_hidden)\n",
    "        from_probs = F.log_softmax(from_logits, dim=1)\n",
    "\n",
    "        # Если только предсказание from_square\n",
    "        if from_square is None:\n",
    "            return from_probs, None, [att4]  # Только один attention map\n",
    "\n",
    "        # Голова для целевой клетки\n",
    "        # Создаем one-hot кодирование для from_square на правильном устройстве\n",
    "        from_onehot = torch.zeros(batch_size, 64, 4, 4, device=self.device)\n",
    "        from_onehot[torch.arange(batch_size, device=self.device), from_square, :, :] = 1\n",
    "\n",
    "        # Конкатенируем ResNet features с one-hot кодированием\n",
    "        to_input = torch.cat([shared_features, from_onehot], dim=1)\n",
    "\n",
    "        # Обработка через сверточные слои\n",
    "        to_features = F.relu(self.to_conv1(to_input))\n",
    "        to_flat = to_features.reshape(to_features.size(0), -1)\n",
    "        to_hidden = F.relu(self.to_fc1(to_flat))\n",
    "        to_hidden = self.to_ln1(to_hidden)\n",
    "        to_logits = self.to_output(to_hidden)\n",
    "        to_probs = F.log_softmax(to_logits, dim=1)\n",
    "\n",
    "        return from_probs, to_probs, [att4]\n",
    "\n",
    "    def to(self, device):\n",
    "        \"\"\"Переопределяем метод to для установки устройства\"\"\"\n",
    "        self.device = device\n",
    "        return super().to(device)\n",
    "\n",
    "class SimplifiedAttention(nn.Module):\n",
    "    \"\"\"Упрощенный attention механизм\"\"\"\n",
    "    def __init__(self, channels, reduction=8):  # Уменьшили reduction\n",
    "        super().__init__()\n",
    "        self.channel_attention = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(channels, channels // reduction, 1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(channels // reduction, channels, 1, bias=False),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        ca = self.channel_attention(x)\n",
    "        return x * ca, ca  # Убрали spatial attention для скорости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9842fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessTrainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        test_loader,\n",
    "        device=\"cpu\",\n",
    "        lr=0.001,\n",
    "        weight_decay=0.01,\n",
    "    ):\n",
    "        self.model = model.to(device)\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.device = device\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "\n",
    "        # Функции потерь для dual-head архитектуры\n",
    "        self.from_criterion = nn.NLLLoss()  # Т.к. используем log_softmax\n",
    "        self.to_criterion = nn.NLLLoss()\n",
    "\n",
    "        # Оптимизатор\n",
    "        self.optimizer = optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=self.lr,\n",
    "            weight_decay=self.weight_decay,\n",
    "        )\n",
    "\n",
    "        # Планировщик learning rate\n",
    "        self.scheduler = optim.lr_scheduler.StepLR(\n",
    "            self.optimizer, step_size=5, gamma=0.1\n",
    "        )\n",
    "\n",
    "        # История обучения\n",
    "        self.history = {\n",
    "            \"train_loss\": [],\n",
    "            \"val_loss\": [],\n",
    "            \"train_from_acc\": [],\n",
    "            \"val_from_acc\": [],\n",
    "            \"train_to_acc\": [],\n",
    "            \"val_to_acc\": [],\n",
    "            \"learning_rate\": [],\n",
    "            \"attention_maps\": []  # Для сохранения примеров attention maps\n",
    "        }\n",
    "\n",
    "    def train_epoch(self):\n",
    "        \"\"\"Одна эпоха обучения для dual-head модели\"\"\"\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        total_from_correct = 0\n",
    "        total_to_correct = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        train_bar = tqdm(self.train_loader, desc=\"Training\")\n",
    "\n",
    "        for batch_idx, (boards, from_targets, to_targets) in enumerate(train_bar):\n",
    "            try:\n",
    "                # Перемещаем данные на device\n",
    "                boards = boards.to(self.device, dtype=torch.float32)\n",
    "                from_targets = from_targets.to(self.device, dtype=torch.long)\n",
    "                to_targets = to_targets.to(self.device, dtype=torch.long)\n",
    "\n",
    "                # Валидация целей\n",
    "                assert from_targets.min() >= 0 and from_targets.max() < 64, \\\n",
    "                    f\"Неверные from_targets: {from_targets.min()}-{from_targets.max()}\"\n",
    "                assert to_targets.min() >= 0 and to_targets.max() < 69, \\\n",
    "                    f\"Неверные to_targets: {to_targets.min()}-{to_targets.max()}\"\n",
    "\n",
    "                # Обнуляем градиенты\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                # Прямой проход через dual-head модель - сначала только from_head\n",
    "                from_probs, _, attention_weights = self.model(boards)\n",
    "\n",
    "                # Вычисляем потери для from_head\n",
    "                from_loss = self.from_criterion(from_probs, from_targets)\n",
    "\n",
    "                # Прямой проход для to_head с истинными from_targets (teacher forcing)\n",
    "                _, to_probs, _ = self.model(boards, from_targets)\n",
    "                to_loss = self.to_criterion(to_probs, to_targets)\n",
    "                \n",
    "                # Комбинируем потери\n",
    "                loss = from_loss + to_loss\n",
    "\n",
    "                # Проверка на NaN\n",
    "                if torch.isnan(loss) or torch.isinf(loss):\n",
    "                    print(f\"Пропуск батча {batch_idx} из-за невалидного loss\")\n",
    "                    continue\n",
    "\n",
    "                # Обратный проход\n",
    "                loss.backward()\n",
    "\n",
    "                # Gradient clipping\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "\n",
    "                # Шаг оптимизатора\n",
    "                self.optimizer.step()\n",
    "\n",
    "                # Статистика\n",
    "                total_loss += loss.item()\n",
    "                batch_size = boards.size(0)\n",
    "                total_samples += batch_size\n",
    "\n",
    "                # Точность для from-square\n",
    "                from_preds = torch.argmax(from_probs, dim=1)\n",
    "                from_correct = (from_preds == from_targets).sum().item()\n",
    "                total_from_correct += from_correct\n",
    "\n",
    "                # Точность для to-square\n",
    "                to_preds = torch.argmax(to_probs, dim=1)\n",
    "                to_correct = (to_preds == to_targets).sum().item()\n",
    "                total_to_correct += to_correct\n",
    "\n",
    "                # Обновляем progress bar\n",
    "                train_bar.set_postfix(\n",
    "                    {\n",
    "                        \"Loss\": f\"{loss.item():.4f}\",\n",
    "                        \"From Acc\": f\"{from_correct / batch_size:.3f}\",\n",
    "                        \"To Acc\": f\"{to_correct / batch_size:.3f}\",\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Ошибка в батче {batch_idx}: {e}\")\n",
    "                continue\n",
    "\n",
    "        # Вычисляем средние метрики за эпоху\n",
    "        avg_loss = total_loss / len(self.train_loader) if len(self.train_loader) > 0 else 0\n",
    "        from_acc = total_from_correct / total_samples if total_samples > 0 else 0\n",
    "        to_acc = total_to_correct / total_samples if total_samples > 0 else 0\n",
    "\n",
    "        return avg_loss, from_acc, to_acc\n",
    "\n",
    "    def validate(self):\n",
    "        \"\"\"Валидация dual-head модели\"\"\"\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        total_from_correct = 0\n",
    "        total_to_correct = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        # Сохраняем пример attention maps для визуализации\n",
    "        sample_attention_maps = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (boards, from_targets, to_targets) in enumerate(tqdm(\n",
    "                self.val_loader, desc=\"Validation\"\n",
    "            )):\n",
    "                try:\n",
    "                    boards = boards.to(self.device, dtype=torch.float32)\n",
    "                    from_targets = from_targets.to(self.device, dtype=torch.long)\n",
    "                    to_targets = to_targets.to(self.device, dtype=torch.long)\n",
    "\n",
    "                    # Прямой проход для from_head\n",
    "                    from_probs, _, attention_weights = self.model(boards)\n",
    "\n",
    "                    # Потери для from_head\n",
    "                    from_loss = self.from_criterion(from_probs, from_targets)\n",
    "\n",
    "                    # Прямой проход для to_head с истинными from_targets\n",
    "                    _, to_probs, _ = self.model(boards, from_targets)\n",
    "                    to_loss = self.to_criterion(to_probs, to_targets)\n",
    "                    \n",
    "                    loss = from_loss + to_loss\n",
    "\n",
    "                    total_loss += loss.item()\n",
    "                    batch_size = boards.size(0)\n",
    "                    total_samples += batch_size\n",
    "\n",
    "                    # Точность\n",
    "                    from_preds = torch.argmax(from_probs, dim=1)\n",
    "                    from_correct = (from_preds == from_targets).sum().item()\n",
    "                    total_from_correct += from_correct\n",
    "\n",
    "                    to_preds = torch.argmax(to_probs, dim=1)\n",
    "                    to_correct = (to_preds == to_targets).sum().item()\n",
    "                    total_to_correct += to_correct\n",
    "\n",
    "                    # Сохраняем attention maps из первого батча\n",
    "                    if batch_idx == 0 and len(sample_attention_maps) == 0:\n",
    "                        sample_attention_maps = attention_weights\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Ошибка в валидационном батче {batch_idx}: {e}\")\n",
    "                    continue\n",
    "\n",
    "        avg_loss = total_loss / len(self.val_loader) if len(self.val_loader) > 0 else 0\n",
    "        from_acc = total_from_correct / total_samples if total_samples > 0 else 0\n",
    "        to_acc = total_to_correct / total_samples if total_samples > 0 else 0\n",
    "\n",
    "        return avg_loss, from_acc, to_acc, sample_attention_maps\n",
    "\n",
    "    def train(self, num_epochs=50, early_stopping_patience=10):\n",
    "        \"\"\"Полный цикл обучения для dual-head модели\"\"\"\n",
    "        best_val_loss = float(\"inf\")\n",
    "        patience_counter = 0\n",
    "\n",
    "        print(\"Начало обучения ResidualCNNWithAttention модели...\")\n",
    "        print(f\"Используется устройство: {self.device}\")\n",
    "        print(f\"Размер тренировочного набора: {len(self.train_loader.dataset)}\")\n",
    "        print(f\"Размер валидационного набора: {len(self.val_loader.dataset)}\")\n",
    "        print(f\"Architecture: ResNet-50 backbone + Attention + Dual Heads\")\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f\"\\nЭпоха {epoch + 1}/{num_epochs}\")\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "            # Обучение\n",
    "            train_loss, train_from_acc, train_to_acc = self.train_epoch()\n",
    "\n",
    "            # Валидация\n",
    "            val_loss, val_from_acc, val_to_acc, attention_maps = self.validate()\n",
    "\n",
    "            # Обновление learning rate\n",
    "            self.scheduler.step(val_loss)\n",
    "            current_lr = self.optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "            # Сохраняем историю\n",
    "            self.history[\"train_loss\"].append(train_loss)\n",
    "            self.history[\"val_loss\"].append(val_loss)\n",
    "            self.history[\"train_from_acc\"].append(train_from_acc)\n",
    "            self.history[\"val_from_acc\"].append(val_from_acc)\n",
    "            self.history[\"train_to_acc\"].append(train_to_acc)\n",
    "            self.history[\"val_to_acc\"].append(val_to_acc)\n",
    "            self.history[\"learning_rate\"].append(current_lr)\n",
    "            self.history[\"attention_maps\"].append(attention_maps)\n",
    "\n",
    "            # Выводим результаты\n",
    "            print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "            print(f\"Train From Acc: {train_from_acc:.4f} | Val From Acc: {val_from_acc:.4f}\")\n",
    "            print(f\"Train To Acc: {train_to_acc:.4f} | Val To Acc: {val_to_acc:.4f}\")\n",
    "            print(f\"Learning Rate: {current_lr:.6f}\")\n",
    "\n",
    "            # Сохранение лучшей модели\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                patience_counter = 0\n",
    "                self.save_model(\"best_chess_resnet_attention_model.pth\")\n",
    "                print(\"Сохранена лучшая модель!\")\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                print(f\"Early stopping: {patience_counter}/{early_stopping_patience}\")\n",
    "\n",
    "            # Early stopping\n",
    "            if patience_counter >= early_stopping_patience:\n",
    "                print(\"Ранняя остановка!\")\n",
    "                break\n",
    "\n",
    "        print(\"\\nОбучение завершено!\")\n",
    "        self.plot_training_history()\n",
    "\n",
    "    def evaluate(self):\n",
    "        \"\"\"Финальная оценка на тестовом наборе\"\"\"\n",
    "        print(\"\\nОценка на тестовом наборе...\")\n",
    "        self.model.eval()\n",
    "\n",
    "        total_from_correct = 0\n",
    "        total_to_correct = 0\n",
    "        total_full_correct = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for boards, from_targets, to_targets in tqdm(\n",
    "                self.test_loader, desc=\"Testing\"\n",
    "            ):\n",
    "                boards = boards.to(self.device, dtype=torch.float32)\n",
    "                from_targets = from_targets.to(self.device, dtype=torch.long)\n",
    "                to_targets = to_targets.to(self.device, dtype=torch.long)\n",
    "\n",
    "                # Предсказание from-square\n",
    "                from_probs, _, _ = self.model(boards)\n",
    "                from_preds = torch.argmax(from_probs, dim=1)\n",
    "\n",
    "                # Предсказание to-square с истинными from-square для оценки качества модели\n",
    "                _, to_probs, _ = self.model(boards, from_targets)\n",
    "                to_preds = torch.argmax(to_probs, dim=1)\n",
    "\n",
    "                # Подсчет правильных предсказаний\n",
    "                batch_size = boards.size(0)\n",
    "                total_samples += batch_size\n",
    "                \n",
    "                from_correct = (from_preds == from_targets).sum().item()\n",
    "                to_correct = (to_preds == to_targets).sum().item()\n",
    "                full_correct = ((from_preds == from_targets) & (to_preds == to_targets)).sum().item()\n",
    "\n",
    "                total_from_correct += from_correct\n",
    "                total_to_correct += to_correct\n",
    "                total_full_correct += full_correct\n",
    "\n",
    "        from_acc = total_from_correct / total_samples if total_samples > 0 else 0\n",
    "        to_acc = total_to_correct / total_samples if total_samples > 0 else 0\n",
    "        full_acc = total_full_correct / total_samples if total_samples > 0 else 0\n",
    "\n",
    "        print(f\"\\nРезультаты на тестовом наборе:\")\n",
    "        print(f\"From-square Accuracy: {from_acc:.4f}\")\n",
    "        print(f\"To-square Accuracy: {to_acc:.4f}\")\n",
    "        print(f\"Full Move Accuracy: {full_acc:.4f}\")\n",
    "\n",
    "        return from_acc, to_acc, full_acc\n",
    "\n",
    "    def predict_single_move(self, board_tensor):\n",
    "        \"\"\"Предсказание хода для одного тензора доски\"\"\"\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            # Предсказываем from_square\n",
    "            from_probs, _, _ = self.model(board_tensor.unsqueeze(0).to(self.device))\n",
    "            from_square = torch.argmax(from_probs, dim=1).item()\n",
    "            \n",
    "            # Предсказываем to_square на основе предсказанного from_square\n",
    "            _, to_probs, attention_weights = self.model(\n",
    "                board_tensor.unsqueeze(0).to(self.device), \n",
    "                torch.tensor([from_square], device=self.device)\n",
    "            )\n",
    "            to_square = torch.argmax(to_probs, dim=1).item()\n",
    "            \n",
    "            return from_square, to_square, attention_weights\n",
    "\n",
    "    def analyze_attention(self, board_tensor):\n",
    "        \"\"\"Анализ attention maps для заданной позиции\"\"\"\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            board_input = board_tensor.unsqueeze(0).to(self.device)\n",
    "            from_probs, _, attention_weights = self.model(board_input)\n",
    "            from_square = torch.argmax(from_probs, dim=1).item()\n",
    "            \n",
    "            # Получаем feature maps для анализа\n",
    "            if hasattr(self.model, 'get_feature_maps'):\n",
    "                feature_maps = self.model.get_feature_maps(board_input)\n",
    "            else:\n",
    "                feature_maps = None\n",
    "            \n",
    "            return {\n",
    "                'from_square_pred': from_square,\n",
    "                'attention_weights': attention_weights,\n",
    "                'feature_maps': feature_maps\n",
    "            }\n",
    "\n",
    "    def save_model(self, path):\n",
    "        \"\"\"Сохранение модели\"\"\"\n",
    "        torch.save(\n",
    "            {\n",
    "                \"model_state_dict\": self.model.state_dict(),\n",
    "                \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "                \"scheduler_state_dict\": self.scheduler.state_dict(),\n",
    "                \"history\": self.history,\n",
    "                \"epoch\": len(self.history[\"train_loss\"]),\n",
    "            },\n",
    "            path,\n",
    "        )\n",
    "\n",
    "    def load_model(self, path):\n",
    "        \"\"\"Загрузка модели\"\"\"\n",
    "        checkpoint = torch.load(path, map_location=self.device)\n",
    "        self.model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        self.optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "        self.scheduler.load_state_dict(checkpoint[\"scheduler_state_dict\"])\n",
    "        self.history = checkpoint[\"history\"]\n",
    "\n",
    "    def plot_training_history(self):\n",
    "        \"\"\"Визуализация истории обучения\"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "        # Потери\n",
    "        epochs = range(1, len(self.history[\"train_loss\"]) + 1)\n",
    "        ax1.plot(epochs, self.history[\"train_loss\"], label=\"Train Loss\", linewidth=2)\n",
    "        ax1.plot(epochs, self.history[\"val_loss\"], label=\"Val Loss\", linewidth=2)\n",
    "        ax1.set_title(\"Потери\", fontsize=14)\n",
    "        ax1.set_xlabel(\"Эпоха\")\n",
    "        ax1.set_ylabel(\"Loss\")\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "\n",
    "        # From-square точность\n",
    "        ax2.plot(epochs, self.history[\"train_from_acc\"], label=\"Train From Acc\", linewidth=2)\n",
    "        ax2.plot(epochs, self.history[\"val_from_acc\"], label=\"Val From Acc\", linewidth=2)\n",
    "        ax2.set_title(\"From-square Точность\", fontsize=14)\n",
    "        ax2.set_xlabel(\"Эпоха\")\n",
    "        ax2.set_ylabel(\"Accuracy\")\n",
    "        ax2.legend()\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "\n",
    "        # To-square точность\n",
    "        ax3.plot(epochs, self.history[\"train_to_acc\"], label=\"Train To Acc\", linewidth=2)\n",
    "        ax3.plot(epochs, self.history[\"val_to_acc\"], label=\"Val To Acc\", linewidth=2)\n",
    "        ax3.set_title(\"To-square Точность\", fontsize=14)\n",
    "        ax3.set_xlabel(\"Эпоха\")\n",
    "        ax3.set_ylabel(\"Accuracy\")\n",
    "        ax3.legend()\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "\n",
    "        # Learning rate\n",
    "        ax4.plot(epochs, self.history[\"learning_rate\"], linewidth=2, color='purple')\n",
    "        ax4.set_title(\"Learning Rate\", fontsize=14)\n",
    "        ax4.set_xlabel(\"Эпоха\")\n",
    "        ax4.set_ylabel(\"LR\")\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "        ax4.set_yscale('log')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"training_history_resnet_attention.png\", dpi=300, bbox_inches=\"tight\")\n",
    "        plt.show()\n",
    "\n",
    "    def plot_attention_maps(self, board_tensor, epoch=-1):\n",
    "        \"\"\"Визуализация attention maps для примера доски\"\"\"\n",
    "        if len(self.history[\"attention_maps\"]) == 0:\n",
    "            print(\"No attention maps available\")\n",
    "        \n",
    "        attention_maps = self.history[\"attention_maps\"][epoch]\n",
    "        if isinstance(attention_maps, list) and len(attention_maps) > 0:\n",
    "            # Берем последний уровень attention (самый высокоуровневый)\n",
    "            attention_map = attention_maps[-1][0].cpu().numpy()  # [1, H, W]\n",
    "        else:\n",
    "            attention_map = attention_maps[0].cpu().numpy() if attention_maps is not None else None\n",
    "        \n",
    "        if attention_map is None:\n",
    "            print(\"No attention map available\")\n",
    "            return\n",
    "            \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        \n",
    "        # Исходная доска\n",
    "        board_vis = board_tensor[:12].sum(dim=0).cpu().numpy()  # Сумма по фигурам\n",
    "        ax1.imshow(board_vis, cmap='RdYlBu_r')\n",
    "        ax1.set_title(\"Шахматная доска\")\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Attention map\n",
    "        im = ax2.imshow(attention_map.squeeze(), cmap='hot', interpolation='nearest')\n",
    "        ax2.set_title(\"Attention Map\")\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        plt.colorbar(im, ax=ax2)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"attention_visualization.png\", dpi=300, bbox_inches=\"tight\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47564f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Используется устройство: {device}\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Загрузка данных\n",
    "    print(\"Загрузка данных...\")\n",
    "    splitter = ChessDataSplitter(\n",
    "        test_ratio=0.01,\n",
    "        val_ratio=0.2 * (1 - 0.01),\n",
    "        train_ratio=0.8 * (1 - 0.01),\n",
    "        csv_file=\"fens_training_set.csv\",\n",
    "        random_state=seed\n",
    "    )\n",
    "    train_dataset, val_dataset, test_dataset = splitter.split_data()\n",
    "    train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "    # Модель\n",
    "    print(\"Инициализация модели...\")\n",
    "    model = ResidualCNNWithAttention()\n",
    "\n",
    "    # Тренер\n",
    "    trainer = ChessTrainer(model, train_loader, val_loader, test_loader, device)\n",
    "\n",
    "    # Обучение\n",
    "    trainer.train(num_epochs=20, early_stopping_patience=10)\n",
    "\n",
    "    # Валидация\n",
    "    trainer.validate()\n",
    "\n",
    "    # # Сохранение финальной модели\n",
    "    # trainer.save_model(\"final_chess_model.pth\")\n",
    "    # print(\"Модель сохранена!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79bfaaea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используется устройство: cuda\n",
      "Загрузка данных...\n",
      "0.792 0.198 0.01\n",
      "Загружено 268549 валидных позиций\n",
      "Разбиение завершено:\n",
      "Train: 212690 samples (79.2%)\n",
      "Val: 53173 samples (19.8%)\n",
      "Test: 2686 samples (1.0%)\n",
      "Инициализация модели...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\dlml\\venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "f:\\dlml\\venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начало обучения ResidualCNNWithAttention модели...\n",
      "Используется устройство: cuda\n",
      "Размер тренировочного набора: 212690\n",
      "Размер валидационного набора: 53173\n",
      "Architecture: ResNet-50 backbone + Attention + Dual Heads\n",
      "\n",
      "Эпоха 1/20\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 208/208 [08:27<00:00,  2.44s/it, Loss=5.8964, From Acc=0.137, To Acc=0.312]\n",
      "Validation: 100%|██████████| 1662/1662 [02:02<00:00, 13.59it/s]\n",
      "f:\\dlml\\venv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6.4809 | Val Loss: 6.3799\n",
      "Train From Acc: 0.1211 | Val From Acc: 0.1232\n",
      "Train To Acc: 0.2346 | Val To Acc: 0.2517\n",
      "Learning Rate: 0.000100\n",
      "Сохранена лучшая модель!\n",
      "\n",
      "Эпоха 2/20\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 208/208 [08:02<00:00,  2.32s/it, Loss=5.7845, From Acc=0.154, To Acc=0.313]\n",
      "Validation: 100%|██████████| 1662/1662 [01:57<00:00, 14.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5.7648 | Val Loss: 5.7616\n",
      "Train From Acc: 0.1654 | Val From Acc: 0.1659\n",
      "Train To Acc: 0.3137 | Val To Acc: 0.3141\n",
      "Learning Rate: 0.000100\n",
      "Сохранена лучшая модель!\n",
      "\n",
      "Эпоха 3/20\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 208/208 [07:33<00:00,  2.18s/it, Loss=5.5682, From Acc=0.194, To Acc=0.338]\n",
      "Validation: 100%|██████████| 1662/1662 [01:54<00:00, 14.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5.6567 | Val Loss: 5.7010\n",
      "Train From Acc: 0.1780 | Val From Acc: 0.1721\n",
      "Train To Acc: 0.3236 | Val To Acc: 0.3182\n",
      "Learning Rate: 0.000100\n",
      "Сохранена лучшая модель!\n",
      "\n",
      "Эпоха 4/20\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 208/208 [07:37<00:00,  2.20s/it, Loss=5.6005, From Acc=0.191, To Acc=0.328]\n",
      "Validation: 100%|██████████| 1662/1662 [01:54<00:00, 14.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5.5644 | Val Loss: 5.6502\n",
      "Train From Acc: 0.1901 | Val From Acc: 0.1811\n",
      "Train To Acc: 0.3319 | Val To Acc: 0.3244\n",
      "Learning Rate: 0.000100\n",
      "Сохранена лучшая модель!\n",
      "\n",
      "Эпоха 5/20\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 208/208 [07:25<00:00,  2.14s/it, Loss=5.4656, From Acc=0.219, To Acc=0.319]\n",
      "Validation: 100%|██████████| 1662/1662 [01:50<00:00, 14.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5.4613 | Val Loss: 5.6158\n",
      "Train From Acc: 0.2033 | Val From Acc: 0.1843\n",
      "Train To Acc: 0.3419 | Val To Acc: 0.3250\n",
      "Learning Rate: 0.000100\n",
      "Сохранена лучшая модель!\n",
      "\n",
      "Эпоха 6/20\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  69%|██████▉   | 144/208 [05:11<02:18,  2.16s/it, Loss=5.2654, From Acc=0.219, To Acc=0.375]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     26\u001b[39m trainer = ChessTrainer(model, train_loader, val_loader, test_loader, device)\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Обучение\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_patience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Валидация\u001b[39;00m\n\u001b[32m     32\u001b[39m trainer.validate()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 211\u001b[39m, in \u001b[36mChessTrainer.train\u001b[39m\u001b[34m(self, num_epochs, early_stopping_patience)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m50\u001b[39m)\n\u001b[32m    210\u001b[39m \u001b[38;5;66;03m# Обучение\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m train_loss, train_from_acc, train_to_acc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[38;5;66;03m# Валидация\u001b[39;00m\n\u001b[32m    214\u001b[39m val_loss, val_from_acc, val_to_acc, attention_maps = \u001b[38;5;28mself\u001b[39m.validate()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 58\u001b[39m, in \u001b[36mChessTrainer.train_epoch\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     54\u001b[39m total_samples = \u001b[32m0\u001b[39m\n\u001b[32m     56\u001b[39m train_bar = tqdm(\u001b[38;5;28mself\u001b[39m.train_loader, desc=\u001b[33m\"\u001b[39m\u001b[33mTraining\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mboards\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_targets\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_bar\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mtry\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Перемещаем данные на device\u001b[39;49;00m\n\u001b[32m     61\u001b[39m \u001b[43m        \u001b[49m\u001b[43mboards\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mboards\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\dlml\\venv\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\dlml\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:734\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    732\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    733\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    737\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    739\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    740\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\dlml\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:790\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    789\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    791\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    792\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\dlml\\venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:50\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_collation:\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.dataset, \u001b[33m\"\u001b[39m\u001b[33m__getitems__\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__:\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     52\u001b[39m         data = [\u001b[38;5;28mself\u001b[39m.dataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\dlml\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:416\u001b[39m, in \u001b[36mSubset.__getitems__\u001b[39m\u001b[34m(self, indices)\u001b[39m\n\u001b[32m    414\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__([\u001b[38;5;28mself\u001b[39m.indices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    415\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 103\u001b[39m, in \u001b[36mDualHeadChessDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m    100\u001b[39m fen = row[\u001b[33m\"\u001b[39m\u001b[33mfen\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    101\u001b[39m move = row[\u001b[33m\"\u001b[39m\u001b[33mmove\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m board_tensor = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_board_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    104\u001b[39m from_label, to_label = \u001b[38;5;28mself\u001b[39m._move_to_dual_labels(move, fen)\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m board_tensor, from_label, to_label\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mDualHeadChessDataset._board_to_tensor\u001b[39m\u001b[34m(self, fen)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_board_to_tensor\u001b[39m(\u001b[38;5;28mself\u001b[39m, fen: \u001b[38;5;28mstr\u001b[39m) -> torch.Tensor:\n\u001b[32m     36\u001b[39m     board = chess.Board(fen)\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     tensor = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# Фигуры (плоскости 0-11)\u001b[39;00m\n\u001b[32m     40\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m square \u001b[38;5;129;01min\u001b[39;00m chess.SQUARES:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a62c66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
